Aide à la communication pour personnes
handicapées et prédiction de texte

Problématique, état des lieux et retour sur trente ans
de recherche en communication augmentée

Jean-Yves Antoine, Denis Maurel

Université François Rabelais Tours, Laboratoire d’Informatique
jean-yves.antoine@univ-tours.fr, denis.maurel@univ-tours.fr


RÉSUMÉ.   Cet article présente un état de l’art des techniques d’ingénierie linguistique
développées au cours des vingt dernières années dans le domaine de l’aide à la
communication pour les personnes handicapées. Après avoir constaté, au fil du temps, que
les méthodes utilisées se sont orientées des approches centrées connaissances vers des
approches centrées données, nous faisons un bilan de l’aide apportée aux personnes
handicapées en nous intéressant à l’évaluation de ces systèmes. Nous concluons en montrant
que cette problématique est en réalité plus vaste puisqu’elle intéresse toutes les applications
de type entrée de texte sur clavier limité.
ABSTRACT. This paper presents a survey of the state of the art in NLP techniques dedicated to
alternative and augmentative communication for disabled people. We show that these
techniques have mostly evolved during the two last decades from knowledge based
approaches to data oriented approaches. Evaluation results give an indication on the
efficiency of these prediction techniques as well as on the real aid provided to the user. As a
conclusion, we show that the question of text prediction concerns on the whole any text entry
application.
MOTS-CLÉS : communication   assistée, prédiction de texte, modèle de langage, évaluation.
KEYWORDS  : alternative and augmentative communication, text prediction, language model,
evaluation.




TAL. Volume 48 – n° 2/2007, pages 9 à 46
10   TAL. Volume 48 – n° 2/2007


1. Introduction : communication assistée et prédiction de texte

    Le TAL a connu au cours des deux dernières décennies un développement qui
s’est traduit par un nombre croissant de réalisations destinées au grand public ou
aux professionnels, faisant passer de domaine de recherche du stade d’une
linguistique computationnelle à celui de l’ingénierie des langues (Cunningham,
1999). Parmi les champs d’application envisageables de l’ingénierie des langues,
l’aide au handicap reste relativement négligée, alors qu’elle répond pourtant à une
attente sociétale forte. Cette situation est variable d’un pays à l’autre. En France, le
soutien institutionnel sur ces questions a été très tardif, en comparaison par exemple
de ce que l’on peut observer dans les pays scandinaves. Cet abandon a fortement
limité le développement de recherches et de pôles industriels forts dans le domaine.
Quoi qu’il en soit, la thématique du handicap reste peu visible dans les recherches
internationales en TAL, peut-être à cause de son caractère résolument
pluridisciplinaire.
    Pourtant, l’enjeu économique de l’aide au handicap est loin d’être négligeable.
Les personnes souffrant d’un handicap reconnu représentent ainsi près d’un français
sur douze. En 2007, 12 % de la population active française déclare avoir un
handicap, même si seulement 4 % des actifs sont officiellement reconnus comme
handicapés. Ces handicaps peuvent remonter à la naissance ou à l’enfance ou
survenir à l’âge adulte (33 % des déficiences sont d’origine accidentelle). C’est ainsi
qu’en France, 300 000 personnes en âge de travailler deviennent handicapées
chaque année. On sait par ailleurs que le vieillissement de la population observé
dans les pays développés est synonyme d’une forte augmentation du nombre de
personnes âgées en situation de perte d’autonomie. La thématique « vieillissement
de la population et handicaps » constitue ainsi une des actions récurrentes des
programmes de recherche coordonnés soutenus par l’Union européenne. Un dernier
chiffre permettra de quantifier le besoin réel de l’aide au handicap : en France, trois
millions de personnes handicapées bénéficient d’une aide humaine ou technique.
    Compte tenu du rôle privilégié accordé à la communication langagière dans nos
sociétés, l’ingénierie des langues constitue, avec la robotique, le domaine
technologique le plus directement concerné par le problème du handicap. Le
développement d’Internet, véritable portail vers le monde extérieur pour les
personnes isolées et dépendantes que sont souvent les personnes handicapées, ne
fait qu’accroître cette demande sociale. Afin d’illustrer l’importance et la diversité
de cette problématique, citons quelques exemples d’applications
   – aide à la saisie de texte sur ordinateur : accélération de la saisie de texte sur
ordinateur pour des personnes ayant un contrôle limité ou inexistant de leurs
membres antérieurs ; aide à la composition de messages pour des personnes
aphasiques ou dyslexiques…
   – compensation d’une modalité défaillante : synthèse vocale à partir du texte
pour des personnes ayant perdu l’usage de la parole. Cette compensation
                                            Modèle adaptatif pour la prédiction de mots     11


s’accompagne le plus souvent d’une aide à la saisie de texte ; vocalisation de
messages pour les personnes aveugles ;
    – assistance à base de langages spécialisés, souvent dans un cadre
professionnel. On trouve ici les langages de commande pour la robotique
d’assistance (Richard et al., 2000), aide à la programmation informatique, à la
rédaction d’articles mathématiques 1 …
Dans cet article, nous focaliserons notre propos sur la problématique de l’aide à la
saisie de texte, qui trouve des applications en dehors du monde du handicap. Celle-
ci s’inscrit dans le cadre plus général de la communication augmentée écrite ou
orale. Étant donné que les systèmes d’aide à la communication utilisent des
synthèses vocales à partir du texte totalement génériques, cette dimension ne sera
pas abordée ici.
2. Aide à la communication pour personnes handicapées

    Les communicateurs, ou systèmes de communication assistée (AAC en anglais,
pour Alternative and Augmentative Communication) ont pour objectif de restaurer
les capacités de communication de personnes qui souffrent d’un handicap moteur
sévère se traduisant par une paralysie des membres (tétraplégie, quadraplégie), une
athétose ou une dyskinésie 2 . Ces déficiences limitent de manière très pénalisante le
contrôle physique de l’environnement. Dans le cas des pathologies les plus
prononcées, les possibilités de communication à l’écrit (écriture manuscrite ou saisie
de texte sur clavier d’ordinateur) sont excessivement réduites. Par ailleurs,
l’insuffisance du contrôle moteur peut concerner jusqu’à l’appareil phonatoire. Dans
ce cas, la communication est également privée de son support oral habituel. Ces
types de handicap correspondent à des pathologies variées :
    – l’infirmité motrice cérébrale (IMC ou cerebral palsy en anglais) est due à un
accident cérébral anténatal (encéphalite durant la grossesse ou anomalie
chromosomique) ou périnatal (accident durant l’accouchement, traumatisme cranier
ou méningite durant la première année de vie). Les atteintes neurologiques qui en
résultent se traduisent par des tableaux cliniques variés : diplégie, tétraplégie ou
encore athétose ou dysarthrie avec difficultés d’élocutions. Souvent, elle
s’accompagne de troubles cognitifs qui peuvent, en particulier, se traduire par des
dysorthographies, voire des aphasies sévères. L’incidence de cette pathologie est
actuellement de 0,6 nouveaux cas pour 1 000 naissances. Heureusement, les degrés



1
  Les travaux les plus avancés dans ce domaine concernent cependant avant tout les systèmes
de lecture et d’écriture pour personnes aveugles (Karshmer et al, 2004 ; Archambault et al.,
2007).
2
  Dans le cas de l’athétose ou de la dyskinésie, les membres (et autres parties du corps) ne
sont pas paralysés. Au contraire, cette pathologie se caractérise par des mouvements
irréguliers et de petites amplitudes totalement involontaires. Cette absence de contrôle moteur
rend souvent très difficile l’utilisation d’un dispositif physique
12   TAL. Volume 48 – n° 2/2007


d’infirmité varient fortement entre les différents patients qui font l’objet d’une
rééducation durant leur jeunesse ;
    – le syndrome d’enfermement (Locked-In Syndrom ou LIS en anglais) résulte
d’un accident vasculaire cérébral (AVC) majeur détruisant le tronc cérébral
responsable de la transmission des ordres moteurs. Il se traduit par une paralysie
complète, à l’exception des clignements de paupières qui peuvent être contrôlés par
le patient. Les facultés cognitives et perceptives de ce dernier restent intactes.
Comme pour tout AVC, cette maladie touche majoritairement les hommes. Cette
atteinte neurologique reste très rare. Cette pathologie se range ainsi dans le cadre
des maladies orphelines ;
    – la sclérose latérale amyotrophique (SLA, ALS en anglais pour Amyotrophic
lateral sclerosis), également appelée maladie de Charcot ou maladie du
motoneurone, est une maladie neurodégénérative. On est ici en présence d’une
destruction progressive et inéluctable des neurones moteurs du patient. Elle se
déclenche généralement entre 40 et 60 ans et se traduit par une paralysie de plus en
plus importante - le clignement des paupières étant généralement le dernier
mouvement autorisé aux stades ultimes de la maladie - pour laquelle on ne dispose
d’aucun traitement. L’utilisation d’une assistance respiratoire permet désormais de
retarder de plusieurs années l’issue fatale de la maladie. On estime à environ 5 000
le nombre de personnes souffrant d’une SLA en France. L’incidence de la maladie
est d’environ un à deux nouveaux cas survenant chaque année pour
100 000 habitants. Ainsi, en France, 800 nouveaux cas sont détectés chaque année ;
    – la myopathie, et en particulier la myopathie de Duchenne (maladie
génétique), se traduit par une dégénérescence progressive des fibres musculaires.
Elle est diagnostiquée dès l’enfance, les patients ayant une espérance de vie
comprise entre 20 et 30 ans. L’évolution de la maladie va de pair avec une perte de
plus en plus marquée du tonus musculaire. À un stade avancé de la maladie,
l’interaction avec l’environnement physique ne peut plus se faire qu’à l’aide de
dispositifs tels qu’un joystick microgravité, qui sert à piloter le fauteuil du patient
mais aussi son ordinateur. L’incidence de la myopathie de Duchenne est
de 1 nouveau cas sur 3 500 naissances de garçon ;
    – enfin, les victimes d’une lésion médullaire (moelle épinière), qui se traduit
entre autres par une paralysie complète ou partielle des membres, représentent la
majeure partie des utilisateurs potentiels des systèmes d’aide à la communication.
Cette lésion peut être due à un traumatique (accident de la route, du travail ou du
sport), mais également à une myélopathie due à une infection, une inflammation ou
à une tumeur. Le degré de paralysie dépendra de la hauteur de la lésion. En France,
30 000 personnes sont atteintes d’une lésion médullaire, 1 000 à 1 500 cas venant
s’ajouter chaque année, le plus souvent à la suite d’un accident automobile. Dans
certains cas, le patient a dû subir une trachéotomie. Le système de suppléance
concernera alors aussi bien la communication orale qu’écrite.
    Quelle que soit la pathologie concernée, les systèmes de communication
augmentée ou alternative doivent proposer à l’utilisateur une aide à la saisie de
                                               Modèle adaptatif pour la prédiction de mots           13


message (et éventuellement leur vocalisation automatique) adaptée à leurs capacités
très réduites d’action sur le monde physique. Cette saisie va s’effectuer sur un
tableau virtuel de symboles (mots, lettres, phonèmes voire icônes pour les patients
aphasiques ou les enfants en début d’apprentissage de la langue) qui est affiché sur
l’écran d’un ordinateur. Le message est construit en sélectionnant successivement
sur le clavier virtuel les symboles qui le composent. Plus précisément, l’utilisation
des ces systèmes de suppléance repose sur trois composants principaux ( figure 1 ).
                                                                                  X          X




                       A     B     C   D   E   F   G   H       Clavier virtuel
                       I     J     K   L   M   N   7   P

                           Q R     S   T   U   V       X

                       Y     Z     1   2   3   4   5   6


         Synthèse
         vocale




                                 Dispositif
                                 d’entrée

Figure 1. Système d’aide à la communication pour personnes handicapées


    Tout d’abord, un dispositif physique joue le rôle de périphérique d’entrée de
l’ordinateur. Cette interface matérielle dépend du geste libre laissé par le handicap.
Il peut s’agir d’un joystick microgravité (figure 1), d’une commande oculaire ou de
détection de clignements de paupière, d’une commande par souffle ( figure 2 , à       X          X




gauche), d’un détecteur de mouvement de la tête ( figure 2 , à droite) ou d’un simple
                                                           X        X




bouton-poussoir, etc.




Figure 2. Deux exemples de dispositifs d’entrée : à gauche, une commande par
détection de souffle ; à droite, un détecteur de mouvements de tête


   Une caractéristique importante est le nombre de degrés de liberté autorisé par ce
dispositif. Le plus souvent, le patient ne peut plus réaliser que l’équivalent d’un
14   TAL. Volume 48 – n° 2/2007


simple clic (commande de type contacteur « tout ou rien »). Dans ce cas, un
dispositif de défilement permet, suivant différentes stratégies qui seront présentées
plus loin, de parcourir tous les éléments du clavier. C’est donc par défilements, puis
clics successifs, que l’utilisateur va sélectionner les éléments du message sur le
clavier virtuel, élément central de l’interaction.
    Le clavier virtuel peut être associé à un éditeur intégré, ou au contraire permettre
le pilotage de toute application externe (éditeur de texte, navigateur Web, client de
messagerie…). Enfin, une synthèse de parole à partir du texte peut-être utilisée pour
vocaliser le message saisi.
     Ainsi constitué, un système d’aide à la communication permet à une personne
lourdement handicapée d’interagir librement avec son entourage, que ce soit par
écrit ou par oral. Dès lors, le problème qui se pose est celui de la lenteur et de la
pénibilité de la composition des messages. Ce problème majeur est particulièrement
manifeste dans le cas d’un clavier virtuel piloté par un simple clic : après chaque
saisie, l’utilisateur doit attendre que le dispositif de défilement à l’écran atteigne
l’item qu’il souhaite désormais sélectionner. Il en résulte des temps de latence très
longs, qui s’accompagnent d’un nécessaire effort d’attention rapidement fatigant.
L’utilisation d’un système de suppléance se traduit ainsi par une vitesse de
communication de un à cinq mots par minute qui est sans commune mesure avec la
communication orale entre personnes valides. Ces observations se retrouvent aussi
bien sur le français (Le Pévédic, 1997) que l’anglais (Alm et al., 1992).

   Type de communication                             Vitesse (mots/minute)
   Communication orale                                                  150
   Communication écrite (écriture manuscrite)                       12 à 16
   Saisie experte sur clavier (secrétaire)                          15 à 20
   Saisie un doigt sur clavier (débutant)                                11
   Saisie handicapé avec système d’aide                                   5
Tableau 1. Exemples de vitesse de communication en français (Le Pévédic, 1997)


    Il est donc nécessaire de proposer des techniques d’optimisation de la saisie et
c’est à ce niveau qu’interviennent les recherches en traitement automatique des
langues (TAL), mais également en interaction homme-machine (IHM). Deux
approches complémentaires sont en fait envisageables pour accélérer la saisie :
   – la première consiste à optimiser le temps d’accès à la touche recherchée,
donc à réduire le temps de défilement pour y accéder. Cette optimisation dépend
de l’organisation générale du clavier (IHM), mais également de la prise en compte
du contexte de saisie ;
    – la seconde approche vise à minimiser le nombre de saisies, en complétant
automatiquement certaines parties du message en fonction du contexte. Peuvent
intervenir ici des techniques de désabréviation et de prédiction de texte.
                                            Modèle adaptatif pour la prédiction de mots   15


    Nous allons maintenant dresser un panorama des techniques relevant du TAL
qui ont été envisagées jusqu’ici pour réaliser ces deux types d’optimisation, en
commençant par la problématique de la sélection rapide de touches sur le clavier
virtuel.
3. Accélérer la saisie : sélection rapide sur le clavier virtuel

    Tout étudiant en Interaction Homme-Machine sait que les claviers QWERTY ou
AZERTY de nos ordinateurs, hérités de la disposition des marteaux des machines à
écrire, ne sont pas optimaux. Le sentiment d’aisance des utilisateurs experts et le
refus d’apprentissage (pourtant rapide) d’un nouveau clavier, ont pourtant empêché
l’émergence de dispositions plus adaptées telles que celle proposé par
August Dvorak, il y a plus de 70 ans (Dvorak et al., 1936).
    À l’opposé, le besoin d’un clavier adapté est ressenti très fortement par les
personnes handicapées utilisatrices d’un système d’aide à la communication 3 . Dans
ce cas, la recherche d’un clavier optimal va dépendre de plusieurs facteurs :
    – la nature du handicap, et plus précisément les capacités de contrôle moteur
dont dispose l’utilisateur. La question principale, de ce point de vue, est de savoir si
l’utilisateur est encore à même de déplacer un pointeur sur l’écran, ou s’il est limité
à une commande de type « tout ou rien » ;
    – la nature statique ou dynamique du clavier, c’est-à-dire la capacité
d’adapter la disposition des touches en fonction du contexte courant de saisie. Il faut
noter que le choix d’un clavier dynamique dépend également du tableau clinique de
l’utilisateur. Si l’adaptation dynamique peut permettre des gains substantiels en
terme de vitesse de communication, elle est également susceptible d’accroître la
charge cognitive. Par ailleurs, certains troubles cognitifs ou perceptifs ne sont pas
compatibles avec une réorganisation dynamique du clavier.
    Lorsque le handicap moteur reste limité, l’utilisateur peut encore avoir la
possibilité d’utiliser un clavier physique adapté. Un patient athétosique léger
utilisera ainsi un guide-doigts pour effectuer une saisie sans erreur. Lorsqu’un
contrôle physique du clavier n’est plus envisageable, il faut s’en remettre à un
clavier virtuel. Ce paragraphe s’intéresse à la saisie rapide sur ce type de clavier.
3.1. Limiter les mouvements du pointeur : clavier optimisé

   Dans le cas d’utilisateurs ayant gardé la capacité de déplacer un pointeur sur un
écran, l’optimisation va consister à limiter la distance de déplacement du curseur.
Cette question concerne les personnes myopathes équipées d’un joystick
microgravité (contrôle physique direct), mais également les patients qui pilotent le
curseur souris avec un dispositif de détection du regard (Eye Gaze Tracking). Ces


3
  Lorsque le handicap n’est pas apparu à l’âge adulte, ces personnes ne sont par ailleurs pas
habituées à un clavier standard sous-optimal.
16   TAL. Volume 48 – n° 2/2007


systèmes peuvent faire appel à des techniques d’imagerie (Sibert et al., 2000) ou
bien observer l’activité des muscles oculaires pour déterminer la direction du regard
(Baretto et al., 2000 ; Felzer Nordman, 2006). Les sélections (clics « souris ») étant
également réalisées par commande oculaire, la principale difficulté rencontrée
réside dans les sélections non voulues (problème du « toucher de Midas »). Notons
enfin que certains dispositifs expérimentaux pilotent la souris à partir de l’analyse
de l’activité cérébrale, technique réservée aux pathologies les plus lourdes. On parle
d’interface cerveau-machine (brain-computer interface), le patient apprenant à
activer certaines zones cérébrales pour diriger le pointeur (Wolpaw et al., 2000).
    Quel que soit le dispositif d’entrée utilisé dans ces cas, la limitation des
déplacements du curseur est bien entendu une priorité. Certains systèmes laissent à
l’utilisateur (ou à son thérapeute) la liberté de définir la position de chaque touche
sur le clavier virtuel. Plutôt que de s’en remettre à l’introspection de l’utilisateur ou
à l’intuition, comme dans le clavier OPTI (MacKenzie et Zhang, 1999), une
disposition plus efficace des touches peut être obtenue par un apprentissage
automatique prenant en compte la fréquence de cooccurrences des lettres dans la
langue. Ainsi, l’organisation du clavier GAG, développé à l’IRIT, se base sur les
bigrammes de mots observés sur un grand corpus d’apprentissage en français. Les
bigrammes nourrissent un algorithme génétique qui place les caractères sur le
clavier afin de minimiser la distance de déplacement moyenne d’une lettre à la
suivante (Raynal et Vigouroux, 2005). De même, le clavier KNITS est un clavier
optimisé pour l’anglais qui a été estimé sur les bigrammes de lettres observées dans
un corpus de trois millions de mots (Lesher, 2000). Un algorithme d’optimisation
procédant par essai-erreur sous forme de permutation de touches, conduit à une
réduction de 35 % des déplacements par rapport à un clavier QWERTY.




Figure 3. Adaptation dynamique du clavier KeyGlass, avec touches contextuelles.
A) après la saisie du caractère « s » B) après la saisie d’un « e »


    Une disposition encore plus optimale peut être atteinte en considérant le contexte
courant de saisie. Cette idée se retrouve sur le clavier KeyGlass ( figure 3 ), qui est
                                                                      X        X




présenté dans ce numéro dans l’article de Mathieu Raynal. Destiné à des patients
myopathes, il s’agit d’un clavier GAG statique auquel s’ajoutent en transparence
des touches contextuelles (Raynal et Vigouroux, 2005b) : dès qu’un caractère est
sélectionné, KeyGlass affiche autour de la touche correspondante les quatre lettres
                                         Modèle adaptatif pour la prédiction de mots   17


qui lui semblent les plus susceptibles de poursuivre la saisie. La prédiction s’appuie
sur l’interpolation de deux modèles complémentaires : un bigramme de lettres et un
arbre lexicographique probabiliste (cf. infra § 3.4). Le caractère translucide des
touches contextuelles ne masque pas le clavier statique. Cette solution constitue un
bon compromis entre la nécessité d’une certaine stabilité de l’affichage et l’intérêt
de son adaptation dynamique pour faciliter la saisie. Comme nous le verrons tout au
long de cet article, l’adaptation dynamique des claviers virtuels constitue en fait la
question centrale que l’aide à la communication pour personnes handicapées pose
au TAL.
3.2. Commande tout ou rien : clavier statique optimisé

    Lorsque l’utilisateur n’a pas la possibilité de guider un pointeur sur l’écran, le
système doit mettre en œuvre un processus de défilement automatique sur toutes les
touches du clavier. L’utilisateur n’a plus qu’à faire une sélection lorsque la touche
recherchée est atteinte. Il est dès lors important de minimiser le nombre moyen de
défilements. La personne handicapée peut parfois réaliser plusieurs clics différents,
par exemple lorsqu’elle a la capacité de contrôler la longueur de ses appuis ou
lorsqu’elle garde le contrôle de plusieurs gestes. Il est alors possible d’associer une
sémantique différente à chaque type de clic. Certains systèmes utilisent cette
capacité pour laisser à l’utilisateur le pilotage du défilement.
    Dans le cadre de cet article de synthèse, nous nous intéresserons uniquement au
pilotage d’un clavier par clic unique. Notons que la possibilité de gérer des clics
différents ne change pas l’organisation des claviers virtuels. Des études ont
simplement montré qu’une organisation particulière d’un clavier est plus ou moins
adaptée suivant le nombre de clics maîtrisés (Harbush et Kühn, 2003).
    Différents paradigmes de sélection ont été envisagés pour les claviers virtuels.
Deux approches sont le plus souvent mises en œuvre : le balayage linéaire du
clavier, ou le balayage ligne/colonne. Dans ce dernier cas, une sélection nécessite
deux appuis pour sélectionner successivement la ligne et la colonne de la touche
considérée ( figure 4 ).
            X       X




Figure 4. Balayage ligne/colonne : sélection de la ligne (haut) puis de la colonne
18   TAL. Volume 48 – n° 2/2007


    Quel que soit le balayage, il est possible de définir une configuration optimale
suivant le nombre de touches du clavier (Cantegrit et Toulotte, 2001). Pour un
balayage ligne/colonne, on montre aisément que la matrice optimale des touches
forme un triangle rectangle dont les côtés opposés à l’hypoténuse se rejoignent en
haut à gauche de l’écran ( figure 5 ). La disposition des lettres sur la matrice du
                            X       X




clavier dépend de leur fréquence d’apparition dans la langue.
   Le clavier SwitchXS utilise un balayage ligne/colonne en trois clics ( figure 6 ).
                                                                            X       X




Dans un premier temps, l’utilisateur sélectionne une ligne, puis une de ses quatre
sous-parties et enfin le caractère présent dans la sous-ligne considérée.




Figure 5. Clavier optimisé (pour l’anglais) pour un défilement ligne/colonne


    Globalement, chaque type de balayage a ses intérêts et ses inconvénients. Le
balayage ligne/colonne permet une sélection plus rapide du caractère recherché que
le balayage linéaire. À l’opposé, il nécessite un, voire deux (SwitchXS), appuis
supplémentaires, ce qui n’est pas sans conséquence sur la pénibilité de la tâche pour
l’utilisateur handicapé. Par ailleurs, le balayage linéaire ne demande qu’une
attention sur le curseur défilant sur l’interface, alors que le balayage ligne/colonne
nécessite une observation globale du clavier, pour programmer la sélection de la
ligne, puis de la colonne. D’où une charge cognitive plus importante et la nécessité
d’une vision non affectée par le handicap. Le choix d’un balayage particulier
dépendra donc avant tout du tableau clinique de l’utilisateur.




Figure 6. Vue partielle du clavier SwitchXS, avec ses quatre zones de sélection
verticales pour un balayage ligne/colonne optimisé
                                          Modèle adaptatif pour la prédiction de mots   19


   Dans tous les cas, le gain apporté par un clavier standard optimisé reste encore
limité. (Schadle et al., 2002) ont ainsi étudié des claviers français rectangulaires
comportant 64 caractères alphabétiques disposés suivant leur ordre fréquentiel
d’apparition dans la langue. Ils ont observé sur un extrait du corpus Le Monde qu’un
balayage linéaire demandait en moyenne 7,1 défilements pour saisir un caractère,
tandis qu’un balayage ligne/colonne permettait de limiter l’attente à 4,3. Minimiser
plus encore le temps de balayage revient à prendre en considération le contexte
courant de saisie. C’est l’objectif des claviers ambigus et des claviers dynamiques.
3.3. Limiter le nombre de défilements : clavier ambigu

    Le principe des claviers ambigus est bien connu du grand public, puisqu’il est
implémenté pour la saisie de texte sur les téléphones mobiles. L’idée est d’associer à
chaque touche plusieurs caractères, le système ou l’utilisateur étant en charge de
désambiguïser ensuite la saisie. L’objectif des claviers ambigus est bien entendu de
réduire le nombre de touches de saisie. Cette caractéristique présente de nombreux
intérêts pour les claviers virtuels :
    – elle est adaptée à des interfaces de taille réduite, ce qui permet la conception de
systèmes de suppléance portables (Kushler, 1998). La demande pour des dispositifs
discrets, pouvant être installés sur un fauteuil, est forte dans le monde du handicap ;
     – pour des personnes dysarthriques ou athétosiques, elle facilite une saisie sans
erreur par l’augmentation de la taille des touches. Un clavier à quatre touches
autorise ainsi une saisie tactile sur un assistant personnel (PDA) où les quatre coins
de l’écran jouent le rôle de barrière physique remplaçant le guide-doigts (Froehlich
et al., 2007). Une taille de touche accrue est également bienvenue pour les
utilisateurs souffrant de troubles visuels associés ;
    – dans le cas de la saisie de texte par balayage, le nombre de défilements moyen
sera réduit en proportion du nombre de touches, d’où une sélection plus rapide.
    Les systèmes de balayage à clavier ambigu utilisent fréquemment un codage de
type T8/T9 utilisé également sur les téléphones mobiles. Certains systèmes, tel le
clavier UKO (Kühn, 2001), utilisent encore moins de touches ( figure 7 ).
                                                                  X        X




Figure 7. Quelques exemples de claviers ambigus (Harbush, Kühn, 2003)


   La performance d’un système à clavier ambigu va dépendre de sa capacité à
désambiguïser la séquence des touches saisies. Lorsque aucune désambiguïsation
n’est intégrée (ce qui est le cas de la plupart des systèmes commerciaux), un ou
plusieurs appuis supplémentaires vont être nécessaires à l’utilisateur pour préciser
20   TAL. Volume 48 – n° 2/2007


son choix. En pratique, ce type de clavier n’est alors profitable qu’aux utilisateurs
pouvant réaliser deux, trois ou quatre types de clics différents (Harbush, Kühn,
2003b ; Tanaka-Ishii et al., 2002).
    D’autres systèmes réalisent une désambiguïsation automatique partielle en se
basant sur un lexique qui restreint la combinatoire des séquences autorisées de
caractères. Le système T9™, proposé par la société Tegic Communications, se
retrouve sur tous les téléphones mobiles, mais a connu également une application
dans le domaine de l’aide à la communication (Kuhsler, 1998). Il va plus loin en
utilisant un lexique fréquentiel : à tout moment, le système lève l’ambiguïté en
privilégiant la poursuite du mot qui est compatible avec la saisie en cours et qui
présente la fréquence moyenne d’occurrence la plus élevée dans la langue
considérée. Bien entendu, ce choix probabiliste peut être erroné. Dans ce cas,
l’utilisateur doit réaliser un appui supplémentaire pour sélectionner le caractère
correspondant au mot suivant le plus probable. Cette stratégie de rattrapage est
cependant assez rarement utilisée, puisque les performances annoncées sont de
1,0051 appui par caractère. Le système UniGlyph (Belatar, Poirier, 2007) utilise de
même un dictionnaire fréquentiel. Ce clavier original dispose de trois touches
principales correspondant à des primitives graphiques rattachées à un ensemble de
caractères ( figure 8 ). Pour saisir un mot, l’utilisateur sélectionne la suite des
            X        X




primitives correspondantes : après chaque appui, les mots de même longueur les
plus probables (selon le dictionnaire fréquentiel) sont affichés suivant un dispositif
de zoom de type « FishEye ». Lorsque le mot attendu est affiché, on peut le
sélectionner par un ou plusieurs appuis additionnels ; la liste des primitives est ainsi
désambiguïsée. Au final, le système ne nécessite en moyenne que 1,04 appui par
caractères.




Figure 8. Les trois touches correspondant aux primitives du clavier ambigu
UniGlyph et le codage des caractères correspondants (Belatar, Poirier, 2007)


   Quelle que soit la technique retenue, la désambiguïsation ne sera jamais totale.
L’utilisateur d’un clavier ambigu est donc fréquemment amené à réaliser plusieurs
appuis par caractère, ce qui est rapidement fatiguant. C’est pourquoi ces interfaces
sont généralement limitées à des cadres applicatifs bien définis :
                                          Modèle adaptatif pour la prédiction de mots   21


    – saisie avec des dispositifs d’entrée à clics multiples, où la multiplicité des clics
est moins pénalisante. On retrouve ici ce qui existe depuis de nombreuses années en
matière de saisie dactylographique ou de langues orientales à idéogrammes ;
   – saisie sur des interfaces limitées (PDA, téléphone mobile).
    Dans les autres cas de figure, une saisie par balayage linéaire ou ligne/colonne
est recommandée. L’utilisation d’un clavier dynamique constitue une optimisation
très efficace du balayage linéaire
3.4. Limiter le nombre de défilements : clavier dynamique et prédiction de lettre

    Les claviers dynamiques généralisent un principe déjà rencontré avec le système
Keyglass (cf. § 3.1) : la disposition des touches est modifiée après chaque saisie afin
que les caractères les plus probables soient accessibles en un nombre minimal de
défilements ( figure 9 ). L’application de cette idée n’est pas envisageable avec un
              X       X




défilement ligne/colonne. Après chaque remise à jour de l’affichage, l’utilisateur
serait en effet obligé de parcourir visuellement la totalité de l’écran pour découvrir
la nouvelle position de la lettre recherchée. Au contraire, lorsque le clavier virtuel
est utilisé avec un balayage linéaire, le caractère dynamique de l’affichage n’est plus
gênant puisque l’utilisateur n’a qu’à considérer la position courante du curseur et,
éventuellement, celle qui va lui succéder. Deux approches ont principalement été
étudiées jusqu’ici pour mettre en œuvre la prédiction de texte nécessaire à la
réorganisation contextuelle des claviers dynamiques.




Figure 9. Clavier dynamique : exemple de réorganisation du clavier lors de la
saisie du début du mot « compter »


     La première méthode qui généralise l’idée du système T9™, consiste à parcourir
un lexique fréquentiel organisé sous la forme d’un graphe probabiliste de lettres.
(Ménier et Poirier, 2001) proposent ainsi de compiler un lexique fréquentiel sous la
forme d’un arbre. Chaque nœud de l’arbre correspond à un caractère. La probabilité
d’occurrence d’un caractère est donnée par la somme des probabilités de ses nœuds
fils. Les nœuds feuilles, qui correspondent aux mots complétés, ont pour probabilité
finale leur fréquence relative d’occurrence dans la langue.
    L’autre approche s’appuie sur une modélisation markovienne. La première
version du système HandiAS (Le Pévédic, 1998) utilisait ainsi un bigramme de
lettres comme modèle de prédiction. Le système Sibylle, qui est présenté dans ce
22      TAL. Volume 48 – n° 2/2007


numéro, utilise un pentagramme de lettres (contexte de quatre lettres pour prédire la
suivante) qui donne de bons résultats : la lettre recherchée est en moyenne en
troisième position 4 sur un clavier dynamique de 64 touches. Le gain obtenu en
augmentant le contexte de prédiction est négligeable (Schadle et al., 2002). Limiter
ainsi le nombre de défilements moyen à 3 par caractère est déjà très satisfaisant. À
titre de comparaison, un clavier statique à défilement linéaire nécessitera au mieux
9 défilements, tandis qu’un clavier à balayage ligne/colonne optimisé demandera
4,3 défilements, mais également 2 appuis, pour atteindre le même but. Mais l’intérêt
principal de ces approches markoviennes réside dans leur robustesse. Puisqu’elle ne
met pas en jeu de dictionnaire, la prédiction n’est gênée ni par la présence de mots
hors vocabulaire, ni par les erreurs de saisies qui sont très nombreuses dans le cadre
de la communication palliative.
    Dasher est également un clavier dynamique basé sur une prédiction de lettres
(Ward et al., 2000). Son originalité réside dans son interface de saisie. Plutôt que
déplacer le curseur sur le clavier virtuel, l’utilisateur va guider le défilement des
lettres à saisir successivement à l’écran ( figure 10 ).
                                                X          X




Figure 10. Le clavier dynamique Dasher


   La saisie sous Dasher se déroule comme suit. Imaginons que vous désirez écrire
le mot compter. Initialement, les lettres les plus probables sont d, p, l, a et e. Elles

4
    Plus précisément, position 2,9 pour le français et 3,0 pour l’allemand.
                                          Modèle adaptatif pour la prédiction de mots   23


sont affichées sur la droite de l’interface, leur espacement dépendant des
probabilités d’occurrence estimées par le modèle de prédiction. Par exemple, une
lettre ayant une chance sur deux de survenir occupera à elle seule la moitié de
l’interface. Plutôt que de déplacer le curseur vers ces lettres, celles-ci vont se
déplacer pour simuler l’avancement de la saisie. L’utilisateur n’a alors qu’à déplacer
l’affichage vers le haut ou le bas de l’interface, pour se rapprocher de la lettre
désirée. Dans notre cas, le c recherché n’est pas dans les lettres les plus probables. Il
n’est pas donc pas visible initialement. En se rapprochant des lettres affichées les
moins fréquentes (a, e…), les suivantes, par ordre de probabilité, vont apparaître par
effet de zoom. On peut donc diriger le pointeur vers la lettre c qui s’avance
automatiquement vers nous. Ce déplacement automatique s’accompagne
graduellement de l’affichage des lettres qui suivent. La lettre o, qui est la plus
probable après la saisie du c, s’affiche de manière bien distincte. Le texte est ainsi
composé progressivement sans que l’utilisateur n’ait à réaliser un seul appui : il se
contente de diriger l’affichage des lettres vers le haut ou le bas, les lettres étant
sélectionnées lorsque l’on passe sur la zone les concernant. Dasher constitue donc
une tentative originale, et plus poussée que le système KeyGlass, pour utiliser un
clavier dynamique avec un dispositif de pointage encore actif. Dasher peut s’utiliser
avec un dispositif de pointage par détection du regard (Ward et Mc Kay, 2002).
3.5. Autres modalités d’entrée

    Certains systèmes de suppléance ne sont pas concernés par la question de la
saisie sur clavier virtuel. Ils utilisent en effet une autre modalité d’entrée. Lorsqu’un
patient a conservé ses facultés d’élocution, mais a perdu l’usage ou le contrôle de
ses membres, le système n’a pour seul objectif que de permettre une saisie de texte
sur ordinateur. Dans ce cas, l’emploi d’un système de reconnaissance de la parole
peut être conseillé. Les systèmes de dictée vocale présentent désormais des
performances très acceptables et peuvent être adaptés pour prendre en compte
certaines difficultés d’élocution. (Raghavendra et al., 2001) adaptent ainsi le modèle
acoustique d’un système de reconnaissance vocale à l’élocution de patients
dysarthriques. En dépit d’un taux d’erreur de mots (WER pour Word Error Rate)
encore élevé, ils montrent que les transcriptions résultantes sont plus intelligibles
que l’écoute directe de la personne 5 . Dans ce cas, le système peut même servir
d’aide à la communication orale.
   En dépit de ces résultats, de nombreux patients tétraplégiques ne souffrant
d’aucun problème d’élocution préfèrent utiliser un clavier à défilement qu’une
reconnaissance de la parole. Plusieurs facteurs concourent à cet état de fait. Tout
d’abord, la saisie par dictée vocale est moins discrète que la saisie sur clavier, ce qui
peut gêner l’utilisateur. D’autre part, les meilleurs systèmes de reconnaissance à
grand vocabulaire présentent un taux d’erreur de mots qui peut varier de quelques


5
  Ils observent ainsi une augmentation de 22 % à 47 % du nombre de phrases comprises,
suivant le degré de sévérité de la dysarthrie.
24   TAL. Volume 48 – n° 2/2007


pour cent (parole lue ou préparée) à 30 % (parole spontanée). Quelle que soit
l’approche choisie par le système, la correction de ces erreurs par l’utilisateur est le
plus souvent très fastidieuse. Le patient préfère alors souvent s’en remettre à une
saisie directe sur clavier virtuel. De fait, la parole est généralement utilisée comme
modalité d’entrée, ou pour des applications à petit vocabulaire, comme le pilotage
de fauteuil électrique. Dans certains cas, le pilotage du fauteuil peut même conduire
à un minidialogue oral entre l’utilisateur et la machine (Hockey et Miller, 2007).
4. Accélérer la saisie : éviter les sélections

    Comme nous venons de le voir, de multiples approches ont été envisagées pour
réduire le temps d’accès aux touches du clavier virtuel. Ces techniques apportent
généralement des réponses efficaces au problème de la sélection rapide, la tâche des
ergothérapeutes étant alors de choisir l’interface la plus adaptée au handicap de
l’utilisateur.
    En dépit de ces avancées, la saisie de texte reste fastidieuse pour les utilisateurs.
D’où le désir d’accélérer plus encore la composition des messages en évitant à
l’utilisateur la sélection d’un maximum de lettres. L’idée ici est de compléter
automatiquement le texte à la place de l’utilisateur. Deux catégories d’approches,
qui sont par ailleurs le plus souvent complémentaires, sont envisageables ; il s’agit
d’une part des méthodes qui font usage d’abréviations et, d’autre part, de celles
basées sur de la prédiction de mots.
4.1. Écriture abrégée

    Le principe de l’écriture abrégée est connu de toute personne ayant à écrire du
texte de manière rapide. Son utilisation est donc naturelle pour une personne
handicapée ayant une maîtrise correcte de la langue. L’emploi de l’écriture abrégée
est ancien dans le monde du handicap. Elle est courante depuis plusieurs décennies
chez les personnes aveugles qui désirent lire et écrire rapidement des textes sur
claviers adaptés. Il existe ainsi un abrégé Braille II qui consiste en la définition d’un
certain nombre d’abréviations. Leur mémorisation demande bien entendu un effort
d’apprentissage et le décodage de l’écriture abrégée a une influence importante sur
la charge cognitive de la personne. Il existe toutefois des méthodes d’apprentissage
progressif de l’abrégé qui facilitent ces opérations (Ricco et Dutoit, 2001).
    Lorsqu’il existe une correspondance biunivoque entre les abréviations utilisées
et les mots du lexique, la complétion automatique du texte abrégé est directe. La
prise en compte la plus simple de l’écriture abrégée dans le cadre de l’aide à la
communication consiste donc à utiliser un dictionnaire d’abréviations. (Tounsi et
al., 2000) proposent ainsi de retenir les abréviations de mots ou de groupes de
lettres les plus couramment utilisées par l’abrégé Braille II. Le système Sibylle,
décrit dans ce numéro, intègre quant à lui un module qui se base sur les abréviations
définies par l’utilisateur. Point intéressant, ces abréviations sont intégrées en
parallèle dans le modèle de prédiction de mots du système. Ces approches basiques
                                         Modèle adaptatif pour la prédiction de mots   25


à base de dictionnaires d’abréviations se retrouvent dans de nombreux systèmes
commerciaux.
    Si cette approche est très utile pour accélérer la composition les mots les plus
fréquents de la langue, l’utilisation d’un dictionnaire d’abréviations a pour limite les
capacités de mémorisation de ses utilisateurs. En pratique, lorsqu’une personne
utilise l’écriture abrégée, elle utilise des règles morphologiques qui ont l’avantage
de présenter une large couverture lexicale. Par exemple, un utilisateur pourra
décider d’utiliser l’abréviation mt pour représenter le morphème ment qui termine la
plupart des adverbes français. L’aide à la communication à l’aide d’abréviations
requiert donc des modules capables de gérer des règles propres à l’utilisateur et
susceptibles de ne concerner qu’une partie des mots du lexique.
    C’est par exemple l’objectif du projet Hook (Ricco et Dutoit, 2001) qui utilise
des transducteurs pour compléter un texte saisi en écriture abrégée. Plus
précisément, le transducteur est compilé à partir de règles de réécriture multiniveaux
permettant d’encapsuler plusieurs types d’abréviations. Dans l’article cité, le
transducteur MLRR n’était utilisé que pour l’utilisation d’abréviations lexicales. Les
auteurs annonçaient cependant son utilisation future pour le décodage de
morphèmes abrégés dans le cadre du projet européen Fasty.
   Dans le même esprit, le système Compansion (McCoy et al., 1995) détecte des
abréviations à la volée (c’est-à-dire sans que l’utilisateur n’ait eu à les définir) à
partir des règles morphophonétiques les plus souvent utilisées en pratique. Par
exemple, l’élision de certaines lettres d’un mot (bjr pour bonjour). Le système va
même plus loin dans la gestion des abréviations. Il autorise en particulier des
abréviations de nature morphosyntaxique. L’utilisateur peut ainsi rédiger son texte
sous forme télégraphique, sans fléchir les mots. Compansion termine alors la
rédaction par un traitement en trois étapes :
    – analyse syntaxique de surface du texte abrégé : étiquetage en parties du
discours puis parenthésage en segments minimaux non récursifs, encore appelés
chunks (Abney 1991) ;
   – détermination du rôle sémantique de chaque segment sous forme de cas
sémantiques (Fillmore 1968) ;
    – génération/traduction de la forme complétée du texte à partir de ces deux
informations.
    Cette approche est a priori très puissante. Elle pose cependant la question de
l’ambiguïté de la saisie de formes non fléchies, qui peut se traduire par des erreurs
d’expansion. Par ailleurs, elle nécessite une rédaction non naturelle, qui peut gêner
l’utilisateur ayant une bonne maîtrise de la langue, ou au contraire perturber
l’apprentissage de la langue par un jeune enfant. En conclusion, il semble que
l’écriture abrégée doit être limitée à la réduction non ambiguë de morphèmes, avec
éventuellement l’utilisation d’abréviations lexicales pour un nombre limité de mots
26   TAL. Volume 48 – n° 2/2007


très fréquents ou définis pas l’utilisateur. L’écriture abrégée est par ailleurs une
solution complémentaire à la prédiction de mots.
4.2. Prédiction de mots : point de vue utilisateur

    Par opposition à l’écriture abrégée, l’utilisation de la prédiction de mots ne
demande aucun effort de mémorisation. Toutefois, elle peut également accroître la
charge cognitive de l’utilisateur. Son principe est le suivant. Après chaque saisie de
caractère, le système tente de prédire le mot (ou groupe de mots) qui est en cours de
saisie. Lorsque l’utilisateur choisit de retenir une de ces prédictions lexicales, le mot
sélectionné est inséré dans le texte en cours de composition, sans que l’utilisateur
n’ait à composer l’ensemble des lettres qui le composent. L’affichage des
prédictions peut se faire de deux manières principales :
    – complétion intégrée : ici, le système ne prédit qu’un seul mot à chaque saisie.
Cette proposition est directement intégrée au texte en cours de saisie, l’utilisateur
n’ayant qu’à valider par un appui la sélection éventuelle de la proposition. Cette
stratégie de complétion se retrouve par exemple dans le système VITIPI (Boissière
et Dours, 2001). Certains systèmes peuvent proposer une complétion intégrée
partielle, en particulier pour gérer le problème des flexions. Prenons l’exemple de la
saisie d’un verbe conjugué : après la saisie des premières lettres du mot, il est
fréquent qu’on puisse deviner le radical du verbe sans pouvoir prédire son temps et
donc ses suffixes flexionnels. Dans ce cas, le système ne complètera que la partie
non ambiguë du mot (radical), l’utilisateur gérant la saisie des caractères qui
terminent le mot (morphèmes flexionnels) ;
    – liste de mots : lorsque plusieurs propositions sont retenues à chaque fois par le
système, la liste de mots correspondants est affichée dans une zone spécifique du
clavier. Dans ce cas, un appui supplémentaire est nécessaire pour accéder à la liste
de prédiction.
    La prédiction de mots peut a priori accélérer d’une manière significative la
composition des messages. L’évaluation sur corpus de certains systèmes de
prédiction montre qu’ils ont le potentiel d’éviter la saisie d’un caractère sur deux en
moyenne. En pratique, ce gain est toutefois plus limité. On observe en effet que les
patients ignorent souvent les propositions de la prédiction (Biard et al., 2006). Cet
état de fait résulte de l’accroissement de la charge cognitive des utilisateurs, qui
doivent à la fois écrire leur texte et lire les propositions du système. Ce conflit entre
fonctions cognitives antagonistes est a priori moins important dans le cas de la
complétion intégrée. Comme le montrent par exemple (Wandmacher et Antoine,
2007b) dans ce numéro, l’aide apportée par la prédiction de mots est en revanche
moins importante lorsque celle-ci est limitée à une seule proposition. Comme
souvent en communication assistée, l’apport de la prédiction dépendra donc d’un
compromis entre efficacité de la prédiction et adéquation de l’interface homme-
machine du système de suppléance avec le handicap de l’utilisateur. Il n’en reste pas
moins que l’assistance apportée par la prédiction de mots est essentielle. Nous
                                         Modèle adaptatif pour la prédiction de mots   27


allons maintenant présenter les différentes techniques qui ont été développées pour
la réaliser.
4.3. Prédiction de mots : analyse syntaxique et modèles de langages markoviens

    La première idée qui vient à l’esprit en matière de prédiction de mots est
l’utilisation d’un lexique (fréquentiel ou non). Chaque séquence de caractères est
comparée aux mots du dictionnaire et la complétion automatique est possible dès
que le nombre d’items filtrés est suffisamment réduit. À titre d’exemple, le système
VITIPI se limitait dans sa première version à l’exploration d’un lexique fréquentiel
auquel s’ajoutait un module d’apprentissage du lexique personnel de l’utilisateur
(Boissière et Dours, 1996). L’originalité du système est qu’il était capable de
détecter et corriger à la volée des erreurs de saisies simples. VITIPI parvient ainsi à
corriger 72 % des fautes de frappe et 75 % des erreurs dues à une méconnaissance
de l’orthographe du mot.
Des techniques d’optimisation classiques permettent une exploration rapide du
dictionnaire même sur des dispositifs ayant une faible puissance de calcul. C’est
pourquoi ce type de complétion se retrouve sur la plupart des systèmes
commerciaux d’aide à la communication, mais également sur les téléphones
portables ou tout dispositif de saisie à interface limitée.




Figure 11. L’interface utilisateur du système KOMBE


    L’utilisation d’un dictionnaire revêt néanmoins les mêmes faiblesses que celles
entrevues avec la prédiction de lettres : ne pas considérer l’historique du discours
(mots précédents) limite la focalisation de la prédiction. Les premiers systèmes qui
ont considéré un contexte de prédiction plus étendu l’ont fait dans une approche
descendante (au sens des travaux de l’époque en intelligence artificielle) : l’idée
28   TAL. Volume 48 – n° 2/2007


était de partir d’un scénario de communication et de guider l’utilisateur dans la
composition des phrases. C’est par exemple le cas du système Kombe (Guenthner et
al., 1992 ; Richardet, 1998) d’aide à la communication en français et en allemand
pour des patients atteints en particulier de SLA (Sclérose Latérale Amyotrophique).
L’utilisateur compose pas à pas le message en sélectionnant des continuations
possibles (mots ou expressions) produites par le système en fonction du thème de
discussion choisi (santé, nourriture, loisir…), de la syntaxe et du sens de la phrase
en cours de construction. Par exemple (figure 11), si ce qui a été composé jusque-là
est « J’ai beaucoup de difficultés à… », la suite syntaxique possible est, par
exemple, une négation (ne pas), un pronom (te, le, lui, …) ou un ensemble de
verbes. Si l’utilisateur sélectionne plier, Kombe se livrera à un calcul conceptuel
pour afficher les mots et les expressions désignant les parties du corps qui peuvent
être pliées. Kombe est une des premières applications du logiciel générique Illico
(Pasero et Sabatier 1994, 1995) qui, sur la base d’un ensemble de connaissances
(lexiques, règles syntaxiques, règles de composition sémantique, modèle conceptuel,
etc.) permet à la fois d’analyser et de produire des phrases, et si nécessaire de guider
et de corriger l’utilisateur dans la composition de ses énoncés. Dans le même esprit,
le système CHAT repose sur l’utilisation de schémas prédéfinis (Alm et al., 1987 ;
Brophy et al., 1991). (Copestake, 1997) propose de son côté une cogénération basée
sur l’utilisation de schémas prédéfinis que l’utilisateur va compléter tout en étant
aidé par le système. À cette fin, ce dernier utilise des données statistiques sur les
collocations de mots, des grammaires locales et l’utilisation d’ontologies
sémantiques analogues à Wordnet. Plus original enfin, le système Talksback cherche
à retrouver dans une base de phrases préenregistrées, celle qui pourrait aller avec le
contexte courant. L’utilisateur doit sélectionner le sujet de conversation, le type de
phrase et si possible la situation (Broumley et al., 1990).
    La composition assistée permet une saisie très rapide, mais elle se limite à une
communication finalisée, orientée vers un but précis et où le libre arbitre de
l’utilisateur est le plus souvent restreint. En ce sens, elle ne peut tenir lieu de
solution universelle pour l’aide à la communication. Cette approche permet toutefois
de mettre en avant un besoin récurrent en matière de communication alternative :
celui de la rédaction de messages d’urgence, tels que « je suis mal installé sur mon
fauteuil », « je veux aller aux toilettes », etc. Tout système d’aide à la
communication se doit de proposer une méthode de saisie rapide d’un certain
nombre de messages importants pour l’utilisateur. Ainsi, le système Sibylle permet à
l’utilisateur de définir seize messages préenregistrés. La composition assistée peut
être vue comme une amélioration de ces possibilités de communication d’urgence.
   Si l’on vise au contraire une aide à la communication plus générale, il paraît
naturel de se baser sur la prise en considération des structures syntaxiques de la
                                            Modèle adaptatif pour la prédiction de mots    29


langue 6 . De ce point de vue, la prédiction de mots pour la communication palliative
a suivi dans une certaine mesure l’évolution historique du TAL. Jusqu’au début des
années 1990, les approches à base de connaissances sont ainsi restées
prédominantes (Vandykke et al., 1992 ; Swiffin et al., 1987). Elles consistent le plus
souvent à faire l’analyse syntaxique de la phrase en cours de saisie pour prédire le
mot suivant, ou sa partie du discours. Par exemple, le système HandiAS considère
des grammaires locales qui décrivent les séquences de mots ou parties du discours
autorisées dans la langue. Ces grammaires sont en fait décrites sous la forme de
transducteurs qui peuvent facilement être utilisés en prédiction (Maurel et al., 2000).
    Deux problèmes principaux se posent face aux systèmes à base de
connaissances. Tout d’abord, la prédiction n’est utilisable que si l’on sait classer les
différentes hypothèses. Soit parce qu’il ne faut conserver qu’une seule proposition
(complétion intégrée), soit parce qu’il faut choisir les n termes à afficher dans la
liste de prédiction 7 . Pour répondre à cet impératif, on a recours à des systèmes
hybrides combinant analyse syntaxique symbolique et calcul de fréquences. C’est,
entre autres, le cas de HandiAS (Le Pévédic, 1998) et du système SyntaxPAL
(Wright, 1994). Tous les deux combinent grammaires locales et probabilités.
    Le second problème est plus profond : il concerne les difficultés que rencontrent
ces systèmes en cas d’énoncés agrammaticaux. Il n’existe pas d’incompatibilité
fondamentale entre robustesse d’analyse et systèmes à base de connaissances. Le
TAL robuste (Ejerhed, 1993), qui se fonde sur les principes du shallow parsing et
de l’analyse incrémentale (Aït-Moktar et al., 2003) est là pour le rappeler, en
particulier par ses applications sur la parole spontanée (Antoine et al., 2003). Le
problème qui se pose ici n’est donc pas celui de la robustesse, mais de sa gestion du
point de vue de l’utilisateur. Lorsqu’un début d’énoncé est agrammatical, le système
ne peut plus effectuer aucune prédiction, alors qu’on aurait besoin d’une
détérioration graduelle des performances. Cette question est très sensible dans le cas
de l’aide au handicap où les erreurs de saisie sont fréquentes et où la maîtrise de la
langue est parfois imparfaite (enfants en cours d’apprentissage, troubles langagiers
associés...). Ces approches ne sont donc pas utilisables en pratique pour l’aide à la
communication et aucun système commercial ne les emploie. Elles retrouvent en
revanche une utilité dans la perspective d’une aide à l’apprentissage ou à la
rééducation. Dans ce cas, il est très important que le système n’accepte que des
énoncés syntaxiquement corrects. C’est dans cet objectif qu’une version d’HandiAS
a été couplée au système Sibylle d’aide à la communication.



6
  La prise en considération de la sémantique serait, bien entendu, également bienvenue. Elle
se heurte toutefois aux limites actuelles du TAL dans le domaine. Nous présenterons aux
§ 4.3 et 4.4. quelques travaux allant dans cette direction.
7
  En effet, en pratique, un grand nombre de mots sont susceptibles de survenir dans le texte à
un moment donné. Sans classement, l’utilisateur doit saisir plus de lettres afin de réduire le
nombre d’hypothèses à une valeur acceptable.
30   TAL. Volume 48 – n° 2/2007


     Comme la quasi-totalité des systèmes de prédiction actuels, le système Sibylle
repose sur un modèle stochastique de type N-grammaire. À la base, Sibylle utilise
un modèle quadrigramme. C’est-à-dire qu’il estime (à partir d’un apprentissage sur
grand corpus) la probabilité d’occurrence de chaque mot, connaissant les trois
derniers mots saisis. D’autres modèles combinent une N-grammaire avec un modèle
de classe, c’est-à-dire un modèle markovien portant sur les parties du discours de
mots. Par exemple, les systèmes Profet (Carlberger et al., 1997) et Fasty (Trost et
al., 2005) reposent sur l’interpolation d’un bigramme avec un tri-classe. On sait que
les modèles de classe sont sous-optimaux d’un point de vue statistique. Leurs
performances sont toutefois supérieures à celles des modèles de mots lorsque la
taille du corpus d’apprentissage est insuffisante au regard de la dimension du
modèle utilisé. Quel que soit le modèle utilisé, le système de suppléance ne
considère que les hypothèses qui sont cohérentes avec les lettres déjà saisies du mot
courant.
    Les limitations des N-grammaires en termes de gestion des dépendances à
longue distance sont bien connues. Dans le cas de la prédiction de mots, cette
insuffisance est relativement peu pénalisante. Elle ne saurait obérer l’intérêt que
représente la détérioration très graduelle des performances des modèles statistiques
en présence d’énoncés non normés. Certains auteurs ont cependant cherché à utiliser
des modèles stochastiques plus avancés. La première version du système Sibylle
(Schadle et al., 2004) utilisait, par exemple, un modèle structural (Chelba, Jelinek,
2000) basé sur la segmentation de l’énoncé en segments minimaux non récursifs
(chunks). Cette approche permet d’étendre le contexte de prédiction sans augmenter
le nombre de paramètres du modèle. Le module orthographique de la plateforme
PCA, qui est présenté dans ce numéro (Blache et Rauzy, 2007), utilise, quant à lui,
le modèle des patrons (Ron et al., 2006). Cette sous-classe des modèles de Markov
cachés considère des états pouvant correspondre à des séquences de longueurs
variables et non plus des items uniques comme dans le cas des N-grammaires. La
phase d’apprentissage sur corpus permet de sélectionner les séquences optimales
pour la tâche de prédiction. Comme les modèles multigrammes (Deligne et Bimbot,
1995), cette approche permet également d’atteindre des contextes de prédiction plus
longs.
4.4. Prédiction de mots : adaptation à l’utilisateur et au discours

    Comme l’ont montré de nombreuses expériences, les systèmes de prédiction de
mots ont la capacité d’éviter à l’utilisateur entre 40 % et 60 % de saisies. Ces
évaluations ont cependant été réalisées sur des corpus artificiels (généralement des
corpus journalistiques) et l’on constate en pratique que les performances baissent de
manière très sensible sur des corpus plus écologiques (Wandmacher et Antoine,
2006 ; Trnka et McCoy, 2007). C’est pourquoi un système d’aide à la
communication ne sera utilisable que s’il dispose de capacités réelles d’adaptation à
l’utilisateur.
                                         Modèle adaptatif pour la prédiction de mots   31


    Étant donné que les patients répondent à des tableaux cliniques très variés, mais
également qu’ils vont utiliser le système pour des usages variés relevant de registres
différents (communication écrite ou orale, rédaction de documents écrits, voire
d’œuvres littéraires), l’aide à la communication doit faire face à des demandes très
fortes d’adaptation multifactorielle. Au niveau de l’interface utilisateur, elle se
traduit par une demande d’un paramétrage le plus étendu possible du système : par
exemple, configuration des différentes fonctions sur le clavier, durée des appuis de
sélection, vitesse de défilement du balayage, etc. Lorsque l’on considère la
prédiction, l’important est que le moteur linguistique prenne en compte la manière
de s’exprimer de l’utilisateur. C’est-à-dire que le système doit considérer dans ses
prédictions :
    – le vocabulaire de l’utilisateur, qu’il s’agisse des entités nommées, des noms
communs, voire des abréviations. Cette question pose bien entendu le problème
classique en TAL des mots hors vocabulaire, mais peut concerner, tout simplement,
la fréquence d’usages des mots spécifiques aux productions de l’utilisateur ;
    – le style de langage propre à l’utilisateur qui, là encore, ne se traduira pas
tant par l’utilisation de structures syntaxiques spécifiques, mais plutôt par des
fréquences d’usages différentes de celles du corpus d’apprentissage.
   En pratique, les modules de prédiction les moins évolués se contentent de créer
un dictionnaire propre à l’utilisateur. Il est préférable que ce lexique spécifique soit
nourri à la volée lors des saisies de l’utilisateur. Lorsque la prédiction classe les
propositions de mots suivant leurs probabilités d’occurrence, il est nécessaire de
combiner fréquences globales et fréquences utilisateur. Dans le cas d’un système de
prédiction hybride, cette combinaison est le plus souvent confiée à une heuristique
ad hoc. Plus original, le système PCA orthographique, présenté dans ce numéro,
mémorise toutes les phrases produites par l’utilisateur sous forme d’arbre (Blache et
Rauzy, 2007), pondéré par les fréquences d’utilisation des énoncés. Cette adaptation
va donc au-delà de la simple création d’un dictionnaire utilisateur. Le calcul final
des probabilités du système est, là encore, obtenu à l’aide d’une heuristique ad hoc
avec seuil maximal d’influence du modèle utilisateur.
    À l’opposé, l’adaptation des modèles de langages stochastiques est une
problématique bien définie d’un point de vue mathématique : on interpole un
modèle de langue général, entraîné sur un grand corpus, avec un modèle spécifique
appris sur les saisies de l’utilisateur (Trost et al., 2005). Le coefficient
d’interpolation entre les deux modèles est donné par un algorithme qui assure de
l’optimalité de la solution pour un critère statistique choisi. L’algorithme
d’interpolation le plus fréquemment retenu est certainement l’algorithme EM, qui
cherche à maximiser l’entropie globale du modèle interpolé (Jelinek, 1990). Il est
intéressant de noter que le coefficient d’interpolation évolue au cours de
l’adaptation afin de refléter au mieux l’apport des saisies de l’utilisateur
(Wandmacher et Antoine, 2007 : 10).
32   TAL. Volume 48 – n° 2/2007


    En utilisant une procédure incrémentale d’évaluation (Boissière et al., 2007), on
peut montrer que les effets de l’adaptation utilisateur sont assez rapides. Ainsi, on
peut déjà détecter une amélioration des performances après la saisie de quelques
milliers de mots (Wandmacher et al., 2007), (figure 5). Les expériences qui ont été
conduites montrent que l’adaptation se traduit initialement par une nette réduction
du taux de mots hors vocabulaire (Boissière et al., 2007). Les améliorations
ultérieures, plus limitées en importance, semblent être plutôt dues à une adaptation
aux structures de phrases utilisées de manière privilégiées par l’utilisateur.
    Les différentes méthodes d’adaptation que nous venons de présenter permettent
une amélioration significative des performances qui est nécessaire à l’utilisation en
pratique de la prédiction de mots. Elles ne permettent néanmoins qu’une adaptation
à long terme du système, alors qu’une focalisation à court terme de la prédiction sur
le thème courant du discours serait également très utile. Cette focalisation est bien
entendu fondatrice pour les systèmes de cogénération finalisée que nous avons
évoqués plus haut (Copestake, 1997 ; Richardet, 1998). Elle a également été étudiée
par quelques systèmes de suppléance à portée générale. Ainsi, le système PAL
(Wright, 1994) estime la probabilité d’occurrence de chaque mot en pondérant sa
fréquence d’usage générale dans la langue par sa fréquence d’utilisation récente
(fenêtre de contexte) par l’utilisateur. L’idée est qu’un mot qui est apparu
récemment est susceptible d’être réutilisé à nouveau dans un avenir très proche,
puisque appartenant au thème courant du discours. Cette idée est la base du modèle
cache qui consiste à garder les n derniers mots qui ont été composés et à augmenter
leur probabilité d’un facteur p constant (Kuhn et De Mori, 1990) ou décroissant
dans le temps (Clarkson et Robinson, 1997). Le modèle cache est très utilisé pour
l’adaptation à court terme des modèles de langage stochastique. L’amélioration des
performances qui en résulte est constante, mais assez limitée dans l’absolu. Une
autre approche, le modèle trigger ne considère pas les mots isolément, mais utilise
des collocations. Dans ce modèle un mot déclencheur augmente (dès qu’il est
utilisé) la probabilité d’autres mots associés (Rosenfeld, 1996 ; Matiasek et Baroni,
2003). Là encore, les gains observés sont réels mais limités.
    La faiblesse (relative) de ces approches est aisément compréhensible. S’ils sont
robustes, les modèles cache et trigger ne donnent en effet qu’une vision très limitée
du thème courant du discours. L’idéal serait de caractériser explicitement quelques
grands thèmes de discours, de détecter le thème courant et de focaliser la prédiction
sur le modèle correspondant. Le manque de robustesse actuel de méthodes de
détection automatique de thème du discours (Bigi et al., 2001) obère cependant leur
application directe dans le domaine de la communication assistée. (Trnka et al.,
2005) résolvent ce hiatus d’une manière séduisante : plutôt que de caractériser un
thème courant unique, ils estiment la probabilité qu’a le discours de se trouver dans
chacun des grands thèmes connus du système. La prédiction est alors réalisée par
l’interpolation de plusieurs modèles de langage spécifiques à chaque thème, les
coefficients d’interpolation correspondant aux probabilités de se trouver dans le
thème considéré.
                                         Modèle adaptatif pour la prédiction de mots   33


    Une dernière approche consiste à ne pas caractériser explicitement le thème du
discours, mais à tenter de circonscrire son champ sémantique. Le système Sibylle
utilise ainsi l’analyse sémantique latente, ou LSA (Deerwester et al., 1990), pour
représenter la sémantique de chaque mot ou texte dans un espace vectoriel. Un
calcul de proximité dans cet espace vectoriel permet d’estimer la probabilité
d’occurrence d’un mot compte tenu du champ sémantique du thème du discours,
défini par les N derniers mots composés par l’utilisateur. Cette prédiction
sémantique est alors interpolée avec un modèle de langage traditionnel. Cette
approche conduit à des gains modérés dans l’absolu, mais déjà dix fois plus
importants que ceux obtenus avec un modèle cache (Antoine et Wandmacher,
2006).
5. Communiquer sans langage verbal

    Les systèmes de suppléance que nous avons étudiés jusqu’à présent s’adressent à
des utilisateurs ayant une maîtrise correcte de la langue. Bien souvent, le patient
souffre pourtant de troubles langagiers associés, ou n’a encore atteint qu’un stade
intermédiaire dans l’apprentissage de la langue. Dans ces situations, il est nécessaire
de développer une interface de saisie adaptée aux capacités langagières de
l’utilisateur.
5.1. Troubles du langage et dysorthographies

    Les troubles langagiers associés à des pathologies telles que l’infirmité motrice
cérébrale se traduisent généralement par une dysorthographie plus ou moins
prononcée. Peu de travaux se sont penchés sur ces problèmes jusqu’à une date
récente. VITIPI, qui a été pionnier en la matière (Boissiere et Dours, 1996), ne gère
ainsi que des problèmes de paragraphie littérale (Boissière et al., 2007) assez limités
(inversion de lettres, par exemple). Ces travaux, comme ceux de (Spooner, 1998) ou
de (Pedler, 2001), peuvent être considérés comme l’adaptation de correcteurs
orthographiques aux erreurs spécifiques aux troubles considérés.
    Ces approches ne sont efficaces que si les dysorthographies restent internes au
mot. Malheureusement, ces erreurs perturbent le plus souvent la segmentation de
l’énoncé en mots, ce qui limite drastiquement l’utilité de ces correcteurs
orthographiques (James et Draffan, 2004). Les travaux de (Sitbon, Bellot et Blache,
2007, 2007b), publiés dans ce numéro spécial, constituent au contraire une réponse
assez globale et élégante à la prise en compte de la dyslexie et des dysorthographies.
Partant de l’analyse des troubles langagiers considérés (Ramus et al., 2003), elle
consiste à compenser les déficits du module phonologique cognitif en réutilisant des
techniques développées initialement par les industries de la parole. Le système
propose en effet de réécrire les énoncés dysorthographiés en deux étapes : après
avoir été repris par un correcteur orthographique, l’énoncé est tout d’abord
phonétisé (reprise d’un module utilisé en synthèse de la parole), puis transcrit par un
module adapté de reconnaissance de la parole.
34    TAL. Volume 48 – n° 2/2007


    Si le recours à une transcription phonétique est utile dans le cas de la dyslexie,
c’est également un passage souvent obligé lors de l’apprentissage de la langue.
Ainsi, les enfants infirmes moteurs cérébraux, qui atteignent un premier stade
d’apprentissage symbolique de la langue, utilisent fréquemment un alphabet
phonétique en compagnie de leur orthophoniste. Des systèmes comme SYNTHE4 ou
CLAPOTI (Vella et al., 2003) sont alors là pour assister la communication.
5.2. Aphasies et communication sans support verbal

    Mais lorsque le patient est aphasique où n’a encore aucune maîtrise de la langue,
le support de la communication est nécessairement iconique. On se retrouve alors
face à un problème de génération de texte : traduire sous forme de message textuel
compréhensible une suite de pictogrammes représentant en règle générale chacun un
concept. La communication assistée à support non verbal est souvent identifiée à
l’utilisation de BLISS (Bliss, 1965). Très utilisé, BLISS n’est pas un simple code
iconique mais un véritable langage conceptuel avec des règles de composition
permettant de créer de nouveaux concepts à partir de 3 000 symboles de base
(figure 12). Cette caractéristique permet à BLISS d’atteindre une grande richesse
d’expression. Elle nécessite en contrepartie des capacités cognitives que n’ont pas
tous les patients et n’offre pas de solutions triviales pour la transcription directe et
automatique d’une séquence BLISS en langage écrit. Minspeak (Baker, 1982), qui
offre des possibilités analogues, présente les mêmes limitations.




Figure 12. Quelques exemples d’icônes BLISS


    D’autres approches ont donc été envisagées, dont l’objectif est de viser une
correspondance simple, non compositionnelle, entre lexique et langage. Dans ce
cadre, chaque pictogramme représente un mot de la langue, et la tâche du système
est de reformuler une séquence télégraphique de mots, d’une manière un peu
analogue au projet Compansion (McCoy et al., 1997 ; McCoy, 1997) d’écriture
télégraphique. Par exemple :
     je / non / avoir mal / tête    reformulé en       je n’ai pas mal à la tête
    La question de l’affordance de la base de pictogrammes retenue est essentielle.
L’utilisation d’icônes animés dans le système Axelia (Abraham, 2000) est très
intéressante de ce point de vue.
                                         Modèle adaptatif pour la prédiction de mots   35


    La principale question posée par l’aide à la communication non verbale réside
toutefois dans le statut linguistique des pictogrammes utilisés et dans la
reformulation orthographique de la séquence d’icônes sélectionnés. Pour répondre à
cette question, le projet PVI (Vaillant, 1997) adopte une démarche très ambitieuse
puisqu’il autorise la définition d’icônes ambigus pouvant correspondre à plusieurs
termes. Par exemple, l’image d’un verre peut représenter dans PVI aussi bien cet
objet que toute boisson ou l’action de boire. À chaque icône est associé un ensemble
de sèmes, au sens de la sémantique structurale (Rastier, 1987). La reformulation
sous forme orthographique suppose une désambiguïsation par propagation
isotopique des sèmes. Cette approche souffre d’une trop grande surgénérativité qui
empêche son utilisation pratique.
    Pour réduire l’ambiguïté, il est préférable d’associer au minimum une catégorie
grammaticale aux pictogrammes, ce qui facilite également l’attribution d’une
fonction syntaxique à chaque icône de l’énoncé lors du processus de reformulation.
C’est cette démarche qui est suivie par la version non verbale de la PCA (Blache et
Rauzy, 2006) et par le système Axelia (Abraham, 2000, 2006). Axelia et PCA
utilisent des catégories syntaxiques élémentaires (figure 13) afin, d’une part, de
faciliter leur appréhension par l’utilisateur, mais également de permettre à ce dernier
d’ajouter aisément de nouveaux pictogrammes et de les associer à une catégorie.




Figure 13. L’interface de la Plateforme de Communication Assistée (PCA) en
mode iconique de saisie (Blache et Rauzy, 2006). On remarque qu’outre la
reformulation des énoncés, le système met en œuvre une prédiction de
mots/concepts (droite de l’interface)
36      TAL. Volume 48 – n° 2/2007


    Dans la PCA, la reformulation est basée sur une grammaire d’arbres adjoints
(TAG), dont les arbres sont surspécifiés. Par exemple, l’arbre lexical associé à un
pictogramme représentant un nom commun porte une seconde feuille lexicale qui
spécifie son déterminant : celui-ci est en effet le plus souvent omis en écriture
pictographique.
    Dans Axelia, la reformulation se fonde sur l’application d’une grammaire
applicative et cognitive. Axelia insiste sur la traduction explicite par les icônes des
marques de flexions et autres traces grammaticales. C’est également la raison pour
laquelle les prépositions, les articles 8 et autres mots grammaticaux doivent être
explicitement écrits. Si l’on reprend l’exemple « je n’ai pas mal à la tête », on écrira
ainsi sous Axelia :
                                       je neg avoir mal à tête
Les couleurs représentent les catégories grammaticales des mots (figure 14) et neg
est le pictogramme du discordantiel représentant la négation.




Figure 14. L’interface du système Axelia montrant l’organisation du lexique. On
remarque la forme hexagonale des touches virtuelle et les codes couleurs associés à
chaque catégorie grammaticale de mots




8
    Par défaut, l’article défini est engendré ; les autres articles doivent être écrits explicitement.
                                         Modèle adaptatif pour la prédiction de mots   37


6. Évaluation

    L’évaluation des systèmes de communication assistée revêt une importance
cruciale du fait de leur visée applicative directe. Comme pour tout logiciel interactif,
elle peut concerner le système dans sa globalité ou chacun de ses composants (black
box ou glass box methodology) et peut mettre en œuvre des paradigmes de tests
objectifs ou subjectifs. Sa mise en œuvre et son exploitation sont cependant
compliquées par différents facteurs :
– manque de généricité : du fait de l’extrême diversité des handicaps et des
tableaux cliniques des patients, il est impossible de conduire des expérimentations
sur un panel d’utilisateurs représentatifs ;
– manque de données de tests : compte tenu de la lenteur de composition des
messages, le recueil d’un corpus de tests écologiques se heurte à une limitation de la
taille des données ;
– manque de naturalité des données : on ne peut recueillir de corpus de tests réels
qu’à partir de sessions d’utilisation sur un système de communication assistée. Or,
on sait que tout système de suppléance influe sur les productions des utilisateurs.
Par exemple, il a été montré que les utilisateurs du système Sibylle faisaient moins
d’erreurs qu’avec le système qu’ils utilisaient auparavant au centre de Kerpape. Il y
a donc un biais dû au système utilisé pour le recueil des données ;
– absence de comparaison directe : l’adaptation à un nouveau système de
suppléance représente un effort très lourd pour une personne fortement handicapée.
Il n’est donc pas envisageable de demander à une personne d’utiliser plusieurs
systèmes concurremment afin de comparer directement ces différents outils.
    Cet ensemble de contraintes limite donc fortement la représentativité des
évaluations conduites. On peut trouver dans la littérature des tests en conditions
réelles où l’on observe le gain en termes de vitesse de saisie (voire son évolution au
cours de l’adaptation au système) autorisée par un système donné. Il faut toutefois
s’interroger pour savoir si ces résultats sont généralisables à d’autres utilisateurs.
C’est pourquoi la plupart des évaluations se résument au test d’un composant
particulier du système sur des données souvent bien artificielles. En particulier, si
quelques auteurs ont cherché à évaluer leur système sur différents registres de
langue (Trnka et Mc Coy, 2007 ; Wandmacher et Antoine 2006), voire sur des
productions de personnes handicapées, la majorité des résultats actuels ont été
obtenus sur des corpus journalistiques bien éloignés des besoins réels des
utilisateurs finaux.
6.1. Évaluation de la rapidité et de la pénibilité de saisie d’une lettre

    Lorsque l’on s’intéresse à la composante TAL de la communication assistée,
différentes métriques objectives peuvent être employées en fonction de la finalité du
composant testé, en rappelant que les attentes de l’utilisateur sont triples a priori :
38   TAL. Volume 48 – n° 2/2007


communiquer plus rapidement, mais également avec moins d’effort (physique et/ou
cognitif) et éventuellement en produisant moins d’erreurs.
    Si l’objectif est d’accélérer la sélection des touches (cf. § 3), la métrique la plus
utilisée est le nombre moyen de défilements nécessaire pour atteindre une lettre.
On peut estimer la pénibilité du processus par le nombre moyen d’appuis par
sélection (KSPC : Keystroke Per Character). La vitesse de balayage choisie par
l’utilisateur permet par ailleurs une estimation des vitesses moyennes de
composition de message. Dans le cas où le patient peut encore utiliser un dispositif
de pointage, la mesure la plus importante est la distance moyenne des déplacements
entre chaque sélection. Dans ce cas, des modèles psychomoteurs sur les temps de
pointage (Fitts, 1954 ; MacKenzie, 1992 ; Soukoreff et MacKenzie, 1995) ou de
recherche visuelle (Hick, 1952 ; Hyman, 1953) donnent une estimation de la vitesse
de composition de messages.
    Lorsque l’on utilise un clavier ambigu, l’objectif central est de limiter le nombre
d’appuis nécessaire pour désambiguïser la sélection. Les claviers ambigus les plus
efficaces sont à même d’atteindre des KPC théoriques très proches de un. Le KPC
constituera donc une bonne estimation des performances du système. (Soukoreff et
MacKenzie, 2003) le considèrent également comme un bon indicateur du taux
d’erreurs faites par l’utilisateur. Bien entendu, on n’intercepte ainsi que les erreurs
qui donnent lieu à correction par l’utilisateur.
6.2. Évaluation de la prédiction de mots

    L’objectif de la prédiction de mots est d’éviter à l’utilisateur le maximum de
saisies. Les métriques qui sont utilisées pour son évaluation peuvent concerner
directement cet objectif ou s’en remettre à l’estimation de la qualité intrinsèque des
prédictions. Les deux approches sont, bien entendu, corrélées. On distingue en
particulier (Fasly et Hirst, 2003) :
– le taux d’économie de saisie (KSR pour Keystroke Saving Rate) exprime le
pourcentage moyen d’appuis qui sont évités grâce à la prédiction. Il est calculé pour
une taille de liste de prédictions donnée. Les performances des systèmes actuels
tournent autour des 50 %, ce qui signifie qu’un appui sur deux est évité en
moyenne. Certains travaux ont cherché à estimer la valeur maximum du KSR qu’il
est possible d’atteindre en théorie (Copestake, 1997). Ce seuil est généralement
situé autour de 60 %, mais certains systèmes tel Sibylle sont à même de l’atteindre
sur certains corpus de test, ce qui relativise la portée de ces réflexions. Il est
toutefois évident que les gains que l’on peut encore espérer à ce niveau de
performance sont marginaux. Notons enfin que le KSR concerne les appuis et non
pas les lettres non saisies. En effet, la stratégie de complétion peut nécessiter des
appuis supplémentaires, par exemple pour atteindre la liste de prédictions. Cette
métrique n’évalue donc pas la prédiction intrinsèque, mais l’association
prédiction/interface/utilisateur.
                                         Modèle adaptatif pour la prédiction de mots   39


– le taux de prédictions correctes (HR pour Hit Rate) évalue le pourcentage de
fois où le mot recherché est proposé dans la liste de prédictions. Ce taux dépend, là
encore, de la taille de la liste de prédictions, et ne dépend pas de la stratégie de
complétion mise en œuvre par l’interface utilisateur. Une mesure complémentaire,
quoique moins répandue, est le nombre moyen d’appuis avant la complétion.
(KuC pour Keystrokes until Completion). Elle donne indirectement une idée du
nombre moyen de lettres qui doivent être saisies dans le mot avant que la prédiction
ne vienne aider l’utilisateur.
    Notons que les métriques classiques en modélisation du langage sont rarement
utilisées dans le domaine de la communication assistée. Même si on a pu observer
une corrélation entre la perplexité ou l’entropie du modèle et la KSR qu’il permet
d’atteindre (Wandmacher et Antoine, 2007b), ces métriques issues de la théorie de
l’information ne constituent pas des indicateurs explicites de l’aide fournie par la
prédiction (Copestake, 1997).
    S’ils donnent des indications sur l’efficacité de l’aide à la communication, ces
paradigmes d’évaluation sont condamnés à rester à l’écart des usages réels. Une
seule expérience suffira à montrer les limites de l’évaluation dans ce domaine de
recherche (Biard et al., 2006). En analysant l’utilisation du système commercial
DIALO par dix patients qui présentaient des pathologies variées (IMC, SLA, anoxie
cérébrale, LIS), les auteurs ont constaté que la prédiction de mots était peu utilisée
et que l’accélération de la composition qu’elle autorisait n’était pas statistiquement
significative. Si le système DIALO présente des imperfections, d’autres études en
arrivent à une conclusion analogue (Anson, 1993 ; Horstmann et al., 1994 ;
Neijmeijer, 2005).
    Ce décalage avec l’estimation des performances de la prédiction ne doit pas
remettre pas en cause l’utilité des métriques utilisées. Ce qu’il faut comprendre,
c’est que ce genre d’évaluation n’indique que la capacité maximale qu’à un moteur
de prédiction à aider l’utilisateur. Partant de là, toute une réflexion doit être menée
sur l’intégration de la prédiction et de la complétion dans l’interface utilisateur du
système de suppléance. Au vu des performances intrinsèques des systèmes de
prédiction actuels, nous pensons que ces considérations ergonomiques doivent
devenir une des priorités de recherche à venir en communication augmentée.
7. Conclusion

    Tout au long de cette synthèse, nous avons cherché à dresser un tableau aussi
complet que possible des techniques TAL utilisées dans le domaine de la
communication augmentée. Un des constats que l’on peut dresser de cet état de l’art
est que l’aide à la communication se nourrit, mais également irrigue une large
palette de problématiques relevant de l’ingénierie des langues. Cette conclusion en
amène une autre qui est bien ancrée parmi les acteurs du domaine : on peut observer
que la plupart des résultats obtenus dans le domaine de l’aide technique pour
personnes handicapées, ont finalement conduit au développement d’outils utiles à
40   TAL. Volume 48 – n° 2/2007


l’ensemble de la population. Les exemples de valorisation de ce type sont très
nombreux et valident le concept de design for all qui est cher aux personnes
handicapées. C’est pourquoi ce numéro spécial est également une invitation à tous
les chercheurs en ingénierie linguistique à s’intéresser à la problématique exigeante,
mais enrichissante, de l’aide à la communication.
Remerciements

   Les auteurs remercient Maryvonne Abraham, Franck Poirier et Paul Sabatier
pour leurs remarques et propositions d’améliorations sur ce texte.

8. Bibliographie
Abney S., « Parsing by chunks », In. Berwick, Abney, Tenny (Eds.) Principle-based parsing.
   Kluwer Academic Publishers. Amsterdam, NL. 1991.
Aït-Mokhtar S., Chanod J.-P., Roux C., « Robustness beyond shallowness : incremental deep
    parsing ». Natural Language Engineering. Vol. 8 (3-2). 2003.
Abraham M., « Reconstruction de phrases oralisées à partir d’une écriture pictographique ».
   Actes Handicap’2000. European Journal of Automation, 34(6-7). p. 803-901. 2000.
Abraham M., « Alterations de la communication dialogique : le statut de la langue dans la
   palliation des troubles de la parole ». Actes Handicap’2006, Paris, France. 2006.
Alm N., Arnott J.L., Newell J.F., Prediction and conversational momentum in an
   augmentative communication system. Communications of the ACM, 35(5). 46-57. 1992.
Alm N., Newell A., Arnott J., « A communication aid which models conversational
   patterns ». In Steele R., Gerrey W. (Eds.) Proc. 10th Annual Conference on
   Rehabilitation Technology. Resna, Washington DC. p. 127-129. 1987.
Anson D., « The effect of word prediction on typing speed ». American Journal of
   Occupational Therapy, 47 (11), p. 1039-1042. 1993.
Antoine J.-Y., Goulian J., Villaneau J., « Quand le TAL robuste s’attaque au langage parlé :
   analyse incrémentale pour la compréhension de la parole spontanée ». Actes TALN’2003.
   Batz-sur-Mer, France, p. 25-34. 2003.
Archambault D., Stöger B., Batusic M., Fahrengruber C., Miesenberger K., « A software
   model to support collaborative mathematical work between Braille and sighted users ».
   Proc. 9th ACM SIGACCESS Conference on Computers and Accessibiliy, ASSETS’07.
   Tempe, AZ. 2007. p. 115-123.
Baker. B.R. « Minspeak, A semantic compaction system that makes self-expression easier for
   communicatively disabled individuals ». Byte, 7(9), p. 186-2002. 1982.
Baretto A.B., Scargle S.D., Adjouadi M., « A practical EMG-based Human Computer
   Interface for users with motor disabilities ». Journal of Rehabilitation Research and
   Development. 37(1). 2000. p. 53-63.
Belatar M., Poirier F., « UniGlyph : une méthode universelle pour la saisie de texte sur
   dispositifs mobiles », Actes IHM’2007, Paris, France, p. 111-118. 2007.
                                            Modèle adaptatif pour la prédiction de mots     41


Bliss C. K., « Semantography (Blissymbolics) ». Semantography Press, Sidney, Australie.
    1965.
Biard N., Dumas C., Bouteille J., Pozzi D., Lofaso F., Laffont I., « Apports de l’évaluation en
    situation de vie à partir d’une étude sur l’intérêt de la prédiction de mots auprès
    d’utilisateurs de synthèse vocale ». Actes Handicap 2006, Paris. p. 145-148. 2006.
Bigi, B. ; Brun, A. ; Haton, J. ; Smaili, K. & Zitouni, I., « Dynamic Topic Identification :
   Towards Combination of Methods », Actes Recent Advances in Natural Language
   Processing workshop, RANLP’2001, p. 255-257. 2001.
Blache Ph., Rauzy S., « Le module de reformulation iconique de la Plateforme de
   Communication Alternative ». Actes TALN’2007, atelier « Reconstruire la langue »,
   Toulouse, France. vol 2, p. 517-528. 2007.
Blache Ph., Rauzy S., « Le moteur de prédiction de mots de la Plateforme de Communication
                                                                                                  Commentaire : On cite le
   Alternative », Traitement Automatique des Langues, TAL, vol. 48 n° 2. 2007.
                                                                                                  numéro en cours : Pourrais-tu
Boissière Ph., Bouraoui J.-L., Vella F., Lagarrigue A., Mojahid M., Vigouroux N.,                 ajouter les pages?
   Nespoulous J.-L., « Méthodologie d’annotation des erreurs en production écrite. Principe
   et résultats préliminaires ». Actes TALN’2007, atelier « Reconstruire la langue »,
   Toulouse, France. vol. 2, p. 529-538. 2007.
Boissière Ph., Dours D., « VITIPI : versatile interpretation of text input by persons with
   impairments ». Proc. 5th International Conference on Computers for Handicapped
   Persons, ICCHP’1996. Linz, Autriche. p. 165-173. 1996.
Boissière Ph., Dours D., « VITIPI : Comment un système d’assistance à l’écriture pour les
   personnes handicapées peut offrir des propriétés intéressantes pour le TALN ? » Actes
   TALN’2001, atelier TALN et Handicap, Tours. Vol. 2, p. 183-192. 2001.
Boissière Ph, Schadle I, Antoine J-Y. « A methodological framework for writing assistance
   systems : applications to Sybille and VITIPI systems », AMSE Journal on Modelling,
   Mesurement & Control, Série C., Barcelona, Spain. Vol. 67, p. 167-176. 2006
Brophy M., Alm N., Newell A., Arnott J., « The effect of a predictive communication aid
   employing speech acts on the conversation of non-vocal speakers », Speech Therapy in
   Practise, 162, p. 46-57. 1991.
Broumley L., Cairns A., Arnott J., « A Case study in applying artificial intelligence in
   personalised communication aid ». Proc. 1st ECART Conference. 1990.
Carlberger A., Carlberger J., Magnuson T., Hunnicutt M.S., Palazuelos-Cagigas S.,
   Navarro S.A., « Profet, a new generation of word prediction : an evaluation study ». Proc.
   Natural Language Processing for Communication Aids, NLPCA’1997. Madrid, Spain.
   p. 23-28. 1997.
Chelba C., Jelinek F., « Structured language modelling ». Computer Speech and Language,
   14(4), p. 283-332. 2000.
Clarkson, P.R., Robinson, A.J., « Language Model Adaptation using Mixtures and an
    Exponentially Decaying Cache », Proc. IEEE ICASSP-97, Munich, Allemagne. p. 799-
    802. 1997.
42   TAL. Volume 48 – n° 2/2007


Cantegrit, B., Toulotte J.M., « Réflexions sur l’aide à la communication des personnes
   présentant un handicap moteur », actes atelier Ingénierie de la langue et handicap,
   TALN’2001, Tours, France. 2001. pp 193-202.
Ann Copestake., « Augmented and alternative NLP techniques for augmentative and
   alternative communication ». Proc. ACL workshop on Natural Language Processing for
   Communication Aids, Madrid, Espagne, p. 37-42. 1997.
Cunningham H., « A definition and short history of Language Engineering », Natural
   Language Engineering, 5(1). 1999. p. 1-16.
Deerwester, S. C., Dumais, S., Landauer, T., Furnas, G. and Harshman, R., « Indexing by
   Latent Semantic Analysis », Journal of the American Society for Information Science,
   JASIS 41(6), p. 391-407. 1990.
Deligne S., Bimbot F., « Language modeling by variable length sequences : theoretical
   formulation and evaluation of multigrams ». Proc. International Conference on Acoustics,
   Speech and Signal Processing, ICASSP’1995, Detroit, MI, p. 172-175. 1995
Dvorak A., Merrick N.L., Dealey W.L., Ford G.C. Typewriting behaviour, American Book
   Company. New-York, NJ. 1936.
Ejerhed E., « Nouveaux courants en analyse syntaxique ». TAL, 34(1), p. 61-82. 2003.
Fazly, A., Hirst, G., « Testing the efficacy of part-of-speech information in word
   completion », Proc. Workshop on Language Modeling for Text Entry Methods,
   EACL’2003. Budapest, Hongrie. 2003.
Felzer T., Nordmann R., « Alternative text entry using different input methods ». Proc. 8th
    ACM SIGACCESS Conference on Computers and Accessibility, ASSETS’06. Portaland,
    OR. 2006. p. 10-17.
Fillmore C.J., « The case for case », in E. Bach, R.T. Harms, « Universal in linguistic
    theory » Holt, Rinehalt and Winston, New-York, NJ, p. 1-90. 1968.
Fitts P.M., « The information capacity of the human motor system in controlling the
    amplitude of movement ». Journal of Experimental Psychology. Vol. 47. p. 381-391.
    1954.
Froehlich J., Wobbrock J.O., Kane S. K. « Barrier pointing : using physical edges to assist
   target acquisition on mobile device touch screen ». Proc. 9th ACM SIGACCESS
   Conference on Computers and Accessibility, ASSETS’07. Tempe, AZ. 2007. p. 19-26.
Guenthner F., Krüger-Thielmann K., Pasero R., Sabatier P. « Communications Aids for ALS
   Patients », Proc. Third International Conference on Computers for Handicapped Persons,
   ICCHP’92, p. 303-307. 1992.
Harbusch K., Kühn M. « An evaluation study of two-button scanning with ambiguous
   keyboards ». Actes 7th Conference for the Advancement of Assistive Technology in
   Europe, AATE’2003. Dublin, Ireland. 2003
Harbusch K., Kühn M. « Towards an adaptive communication aid with text input from
   ambiguous keyboards ». Proc. 10th Conference of the European Chapter of the ACL,
   EACL’2003. 2003b.
                                            Modèle adaptatif pour la prédiction de mots   43


Hick W., « On the rate of gain of information » Quaterly Journal of Experimental
   Psychology. Vol. 4, p. 11-36. 1952.
Hockey B.A., Miller D.P., « A demonstration of a conversationally guided smart
   wheelchair ». Proc. 9th International ACM SIGACCESS Conference on Computers ans
   Accessibility, ASSETS’2007. Phoenix, AZ. 2007. p. 243-244.
Horstmann K.H., Levine S.P. « Modeling the speed of text entry with word prediction
   interface », IEEE Transactions on rehabilitation engineering, 2(3). p. 177-187. 1994.
Hyman R., « Stimulus information as a determinant of reaction time » Journal of
  Experimental Psychology. Vol. 45, p. 188-196. 1953.
James A., Draffan E., « The accuracy of electronic spell checkers for dyslexic learners ».
   PATOSS bulletin. 2004.
Jelinek, F., « Self-organized Language Models for Speech Recognition ». In Waibel A., Lee
    K.-F, Readings in Speech Recognition, Morgan Kaufman Publ. p. 450-506. 1990.
Karshmer A.I., Gupta G., Pontelli E., Miesenberger K., Ammalai N., Gopal D., Batusic M.,
   Stöger B., Palmer B., Guo H.F., « UMA : a system for universal mathematics
   accessibility. » Proc. ACM SIGACCESS Conference on Computers and Accessibility.
   ACM Press, Atlanta. GA. 2004. p. 55-62.
Kuhn, R. and De Mori, R., « A Cache-Based Natural Language Model for Speech
   Reproduction » IEEE Trans. PAMI, 12 (6), p. 570-583. 1990.
Kühn M., Garbe J., « Predictive and highly ambiguous typing for a severely speech and
   motion impaired user. In Stephanidis C. (Ed.) Universal access in Human-Computer
   Interaction. Lawrence Erlbaum, Mahwah, NJ. 2001. p. 933-937.
Kushler C., « AAC using a reduced keyboard », Proc. CSUN Conference on Technology for
   Persons with Disabilities. CSUN’98. California State University, Nortridge, CA. 1998.
Le Pévédic B., « Prédiction morphosyntaxique évolutive dans un système d’aide à la saisie de
   textes pour les personnes handicapées physiques ». Doctorat Université de Nantes,
   France. 1997.
Le Pévédic B., « Les niveaux syntaxiques dans le système HandiAS ». Actes TALN’1998,
   Paris, France. p. 132-141. 1998.
Lesher G.W., Moulton B.J., « A method for optimizing single-finger keyboards ». Proc. Of
   RESNA’2000 Annual Conference. 2000. 91-93.
MacKenzie I.S., « Fitt’s law as a research and design tool ». Human-Computer Interaction.
   Vol. 7. p. 91-139. 1992.
MacKenzie I.S., Zhang S.Z., « The design and evaluation of a high performance soft
   keyboard », Proceedings of the ACM Conference on Human Factors in Computing
   Systems - CHI ‘99. New-York, NJ. 1999. p. 25-31.
Matiasek, H. and Baroni, M., « Exploiting long distance collocational relations in predictive
   typing » Actes EACL’03 Workshop on Language Modeling for Text Entry Methods,
   Budapest. 2003.
44   TAL. Volume 48 – n° 2/2007


Maurel D., Fourche B., Briffaut S., « Aider la communication en favorisant la saisie rapide de
  texte ». Actes Handicap’2000, IFRATH, Paris, France. p. 87-92. 2000.
McCoy K.F., Demasco P., » Some applications of natural language processing to the field of
  augmentative and alternative communication » Actes IJCAI’95 Workshop on Developing
  AI Applications for Disabled People, Montreal, Canada. p. 97-112. 1995.
McCoy K.F., Demasco P.W., Pennington C.A., Luberdorff Badman A. « Some interface
  issues in developing intelligent communication aids for people with disabilities ». Proc.
  Intelligent User Interfaces, IUI’1997. 1997. p. 97-110.
McCoy K.F., « Simple NLP techniques for expanding telegraphic sentences ». Proc.
  workshop on NLP for Communication Aids, ACL/EACL’97, Madrid, Espagne. 1997.
Ménier G., Poirier F., « Système adaptatif de prédiction de texte ». Actes TALN’2001, atelier
  Handicap et Ingénierie des langues. Tours, France. Vol. 2. p. 213-222. 2001.
Niejmeijer D., « In memoriam of Christian Bérard : striving for effort reduction through on-
   screen keyboard word prediction ». Proc. AAATE’2005, Lille, France. 2005
Pasero R., Sabatier P., « Composition de phrases assistée : principes, outils, applications ».
   Actes TALN’94, Marseille, France. p. 51-74. 1994.
Pasero P., Sabatier P., » Guided sentences composition : some problems, solutions and
   applications ». Proc. NLULP’95, Lisboa, Portugal. p. 97-110. 1995.
Pedler J., « The detection and correction of real-word spelling errors in dyslexic text ». Proc.
   4th Annual CLUK Colloquium. p. 115-119. 2001.
Raghavendra P., Rosengren E., Hunnicut S., « An investigation of different degrees of
   dysarthric speech as input to speaker-adaptive and speaker-dependant recognition
   systems. Augmentative and Alternative Communication (AAC). 17(4). 2001. p. 265-275.
Ramus F., Rosen S., Dakin S., Day B., White S., « Theories of developmental dyslexia :
   insights from a multiple cas study of dyslexic adults », Brain, vol. 126. p. 841-865. 2003.
Rastier.F., Sémantique interprétative, PUF, Paris. 1987.
Raynal M., Vigouroux N., « Genetic Algorithm to Generate Optimized Soft Keyboard ».
   Proc. Human Factors in Computing Systems Conference, CHI’2005, Portland.USA. 2005.
   p. 1729-1732.
Raynal M., Vigouroux N., « KeyGlasses : semi-transparent keys to optimize text input on a
   virtual keyboard. » Proc. AAATE’2005. p. 713-717. Lille, France.
Richard P., Gaucher P., Maurel D., « Projet CNHL : Chambre Nomade pour Handicapés
   Lourds» Actes Handicap’2000, Paris, France. 2000. p. 101-107.
Richardet N., « Composition de phrases assistée : un système d’aide à la communication pour
   handicapés ». Thèse de Doctorat Université de la Méditerranée, Marseille, France. 1998.
Ricco, X., Dutoit T., « Vers un logiciel multilingue et gratuit pour l’aide aux personnes
   handicapées de la parole : HOOK ». Actes TALN’2001, atelier Ingénierie des Langues et
   Handicap, Tours, France. 2001. Vol 2, p. 223-232.
                                             Modèle adaptatif pour la prédiction de mots      45


Ron D., Singer Y., Tishby N., « The power of amnesia : learning probabilistic automata with
   variable memory length », Machine Learning, 25, p. 117-149. 1986.
Rosenfeld, R., « A maximum entropy approach to adaptive statistical language modelling ».
   Actes Computer Speech and Language, 10 (1), p. 187-228. 1996.
Schadle I., Antoine J.-Y., Le Pévedic B., Poirier F., « Sibylettre : prédiction de lettre pour la
   communication assistée ». Revue d’Interaction Homme-Machine, RIHM, vol. 3, n° 2.
   2002. p. 115-133.
Schadle I., Antoine J.-Y., Le Pévedic B., Poirier F., « SibyMots : modélisation stochastique
   du langage intégrant la notion de chunks ». Actes TALN’2004, Fès, Maroc. 2004.
Sibert L.E., Jacob R.J., « Evaluation of Eye Gaze Interaction ». Proc. Human Factors in
    Computing Systems Conference, CHI’2000. 2000. p. 281-288.
Sitbon L., Bellot P., Blache Ph., « Traitements phrastiques phonétiques pour la réécriture de
    phrases dysorthographiées », Actes TALN’2007, Toulouse. Vol. 1, p. 263-272. 2007.
Sitbon L., Bellot P., Blache Ph., « Éléments d’adaptation de la recherche d’information pour
    des dyslexiques », TAL, 48(2). 2007.
Soukoreff, R. W., & MacKenzie, I. S., « Metrics for text entry research : An evaluation of
   MSD and KSPC, and a new unified error metric ». Proc. ACM Conference on Human
   Factors in Computing Systems – CHI 2003, New-York, NJ. p. 113-120. 2003.
Soukoreff R.W., MacKenzie I.S., « Theoretical upper and lower bounds on typing speed
   using a stylus and soft keyboard » Behaviour & Information Technology. Vol. 14. p. 370-
   379. 1995.
Spooner R., « A spelling checker for dyslexic users : user modelling for error recovery ».
   PhD thesis. University of York, Heslington. 1998.
Swiffin A.L., Arnott J., Newell A.F., « The use of syntax in a predictive communication aid
   for the physically impaired ». In Steele R., Gerrey W. (Eds.) Proc. 10th Annual
   Conference on Rehabilitation Technology. Resna, Washington DC. p. 124-126. 1987.
Tanaka-Ishii K., Inutsuka Y., Takeichi M., « Entering text with a four-button device. Proc.
   19th International Conference on Computational Linguistics. 2002. p. 988-944.
Tounsi N., Dutoit T., Pagel V., Bagein M., Wynsberghe D., Ruelle A., Malfrère F., « Vers un
   logiciel multilingue et gratuit pour l’aide aux personnes handicapées de la parole : le
   projet W », Actes Handicap’2000, Paris, France. 2000. p. 109-111.
Trnka K., McCoy K.F., « Corpus studies in word prediction » Proc. International ACM
   Conference on Assistive Technologies, ASSETS’2007, Phoenix, AZ. p. 195-202. 2007.
Trnka K., Yarington D., McCoy K.F., Pennington C., « Topic Modeling in Fringe word
   prediction for AAC » Proc. International Conference on Intelligent User Interfaces,
   Sydney, Australie. p. 276-278. 2006.
Trost H., Matiasek J., Baroni, M., « The Language Component of the FASTY Text Prediction
   System ». Applied Artificial Intelligence, 19(8), p. 743-781. 2005
Vaillant P., « Interaction entre modalités sémiotiques : de l’icône à la langue ». Thèse de
   l’université Paris XI, Orsay, France. 1997.
46   TAL. Volume 48 – n° 2/2007


Vandyke J., McCoy K., Demasco P., « Using syntactic knowledge for word prediction ».
   Proc. ISAAC’92. Published in Augmentative and Alternative Communication, 8. p. 163-
   170. 1992.
Vella F., Vigouroux N., Truillet Ph., « CLAPOTI : CLAvier PhOnétique d’aide à la
   communicaTIon orale ». Actes SETIT’2003 (Sciences of Electronic, Technologies of
   Information and Telecommunication), Sousse, Tunisie. CD-ROM. 2003
Wandmacher T., Antoine J.-Y., « Training language models without appropriate language
  resources : experiments with an AAC system for disabled people ». Proc. 5th European
  Conference on Language Resource and Evaluation, LREC’2006. Genova. Italie. 2006.
Wandmacher T., Antoine J.-Y., Poirier F., « Sibylle : a system for alternative communication
  adapting to the context and its user ». Proc. International ACM Conference on Assistive
  Technologies, ASSETS’2007, Phoenix, AZ, p. 203-210. 2007.
Wandmacher T., Antoine J.-Y., « Modèle adaptatif pour la prédiction de mots : adaptation à
  l’utilisateur et au contexte dans le cadre de la communication assistée pour personnes
  handicapées ». TAL. 28(3). ATALA, France. 2007.
Wandmacher T., Antoine J.-Y., « Methods to integrate a language model with semantic
  information for a word prediction component » Actes EMNLP-CoNLL’07, Prague,
  Tchéquie. p. 506-513. 2007b.
Ward D.J., Blackwell A. F., McKay D. J. C., « A data-entry interface using continuous
   gestures and language models ». Proc. 13th Annual ACM Symposium on User Interface
   Software and Technology, UIST’2000. 2000.
Ward D.J., McKay D. J. C., « Fast Hands-free Writing by Gaze Direction ». Nature. 418
   (6900). p. 838. 2002.
Wolpaw J.R., Birbaumer N., Heetderks W.J., McFarland D.J., Peckham P.H., Schalk G.,
  Donchin E., Quatrano L.A., Robinson C.J., Vaughan T.M., « Brain-computer interface
  technology : a review of the first international meeting », IEEE Transactions on Neural
  Systems and Rehabilitation Engineering, 8(2), p. 164-173. 2000.
Wright J., Jones G., Lloyd-Thomas H., « A robust language model incorporating a substring
   parser and extended N-grams. Proc. ICASSP’94. Adelaide, Australia. p. 361-364. 1994.
